{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "feb-v3.ipynb",
      "provenance": [],
      "toc_visible": true,
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/rgumi/seminararbeit_src/blob/master/feb_v3.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oIo03i7VErog",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from scipy.stats import randint, uniform\n",
        "import datetime as dt\n",
        "import numpy as np\n",
        "import pandas as pd \n",
        "import json\n",
        "import urllib.request\n",
        "pd.options.mode.chained_assignment = None\n",
        "\n",
        "from sklearn.model_selection import train_test_split, cross_validate, RandomizedSearchCV, cross_val_score\n",
        "from sklearn.metrics import f1_score, make_scorer, confusion_matrix, accuracy_score, classification_report\n",
        "from sklearn.linear_model import LogisticRegression, SGDClassifier\n",
        "from sklearn.preprocessing import MinMaxScaler\n",
        "from xgboost.sklearn import XGBClassifier\n",
        "from xgboost import XGBRFClassifier\n",
        "\n",
        "import seaborn as sns\n",
        "import matplotlib.pyplot as plt\n",
        "sns.set(style=\"whitegrid\")"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JehFQQjKxDPF",
        "colab_type": "code",
        "outputId": "4068cd84-cfea-41f5-9629-c0a1a0143d25",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 125
        }
      },
      "source": [
        "mountpath = \"/content/drive\"\n",
        "from google.colab import drive\n",
        "drive.mount(mountpath)"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Go to this URL in a browser: https://accounts.google.com/o/oauth2/auth?client_id=947318989803-6bn6qk8qdgf4n4g3pfee6491hc0brc4i.apps.googleusercontent.com&redirect_uri=urn%3aietf%3awg%3aoauth%3a2.0%3aoob&response_type=code&scope=email%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdocs.test%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdrive%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdrive.photos.readonly%20https%3a%2f%2fwww.googleapis.com%2fauth%2fpeopleapi.readonly\n",
            "\n",
            "Enter your authorization code:\n",
            "··········\n",
            "Mounted at /content/drive\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "V9rsfxVlpc1u",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# ['High School', 'University', 'Middle School', 'Professional Training', \n",
        "# 'Elementary School', 'Unknown', 'Illiterate']\n",
        "\n",
        "def group_education(education):\n",
        "  if education in ['Elementary School']:\n",
        "    return 'primary'\n",
        "  if education in ['Middle School', 'High School']:\n",
        "    return 'secondary'\n",
        "  if education in ['University', 'Professional Training']:\n",
        "    return 'tertiary'\n",
        "  return 'unknown'\n",
        "\n",
        "# ['Service provider', 'Student', 'Pensioner', 'Administrator', 'Technician',\n",
        "# 'Blue-collar worker', 'Self-employed', 'Unemployed', 'Manager', 'Housemaid', 'Founder', 'Unknown']\n",
        "\n",
        "def group_job(job):\n",
        "  if job in ['Service provider', 'Housemaid']:\n",
        "    return 'pink-collar worker'\n",
        "  if job in ['Blue-collar worker']:\n",
        "    return 'blue-collar worker'\n",
        "  if job in ['Administrator', 'Manager']:\n",
        "    return 'white-collar worker'\n",
        "  if job in ['Self-employed', 'Founder']:\n",
        "    return 'independent'\n",
        "  return str.lower(job)\n",
        "\n",
        "def group_p_conv(pconv):\n",
        "  if pconv == 'Successful':\n",
        "    return 1\n",
        "  if pconv == 'Failed':\n",
        "    return 2\n",
        "  return 3\n",
        "\n",
        "def group_age(age):\n",
        "  if age < 29:\n",
        "    return 2\n",
        "  if age < 59:\n",
        "    return 3\n",
        "  return 1\n",
        "\n",
        "def group_age_q(age):\n",
        "  if age < 30:\n",
        "    return 1\n",
        "  if age < 35:\n",
        "    return 2\n",
        "  if age < 42:\n",
        "    return 3\n",
        "  if age < 49:\n",
        "    return 4\n",
        "  return 5\n",
        "  \n",
        "def group_duration(duration):\n",
        "  if duration == 0:\n",
        "    return 5\n",
        "  if duration < 60:\n",
        "    return 4\n",
        "  if duration < 300:\n",
        "    return 3\n",
        "  if duration < 600:\n",
        "    return 2\n",
        "  return 1\n",
        "\n",
        "def group_martial_status(status):\n",
        "  if status == 'single':\n",
        "    return 1\n",
        "  if status == 'married':\n",
        "    return 2\n",
        "  if status == 'divorced':\n",
        "    return 3\n",
        "  return 4"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hjf8i_m7vd3C",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "df_euribor = pd.read_csv(\n",
        "    'https://raw.githubusercontent.com/rgumi/seminararbeit_src/master/refined/euribor3m_ref.csv', \n",
        "    index_col=['index'], parse_dates=['date'])\n",
        "\n",
        "df_euribor = df_euribor[(df_euribor['date'].dt.year >= 2007)]\n",
        "\n",
        "def get_euribor(date):\n",
        "  for i in range(0, len(df_euribor)):\n",
        "\n",
        "    if date >= df_euribor['date'].iloc[i]:\n",
        "      last = df_euribor['value'].iloc[i]\n",
        "      continue\n",
        "    return last"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8a8uQAdvOVte",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "df_eurostoxx= pd.read_csv(\n",
        "    'https://raw.githubusercontent.com/rgumi/seminararbeit_src/master/refined/eurostoxx_ref.csv', \n",
        "    index_col=['index'], parse_dates=['date'])\n",
        "\n",
        "df_eurostoxx = df_eurostoxx[(df_eurostoxx['date'].dt.year >= 2007)]\n",
        "\n",
        "def get_eurostoxx(date):\n",
        "  for i in range(0, len(df_eurostoxx)):\n",
        "\n",
        "    if date >= df_eurostoxx['date'].iloc[i]:\n",
        "      last = df_eurostoxx['value'].iloc[i]\n",
        "      continue\n",
        "    return last"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JS4n-_a4OgdJ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "df_fsi= pd.read_csv(\n",
        "    'https://raw.githubusercontent.com/rgumi/seminararbeit_src/master/refined/fsi_ref.csv', \n",
        "    index_col=['index'], parse_dates=['Date'])\n",
        "\n",
        "df_fsi = df_fsi[(df_fsi['Date'].dt.year >= 2007)]\n",
        "\n",
        "def get_fsi(date):\n",
        "  for i in range(0, len(df_fsi)):\n",
        "\n",
        "    if date >= df_fsi['Date'].iloc[i]:\n",
        "      # Possible values: [OFR FSI, Credit, Equity valuation, Safe assets, Funding, Volatility]\n",
        "      last = df_fsi['OFR FSI'].iloc[i]\n",
        "      continue\n",
        "    return last"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "33cyR0R7Llxb",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "df_cpi = pd.read_csv(\n",
        "    'https://raw.githubusercontent.com/rgumi/seminararbeit_src/master/refined/cpi_monthly_ref.csv', \n",
        "    index_col=['index'], parse_dates=['date'])\n",
        "\n",
        "df_cpi = df_cpi[(df_cpi['date'].dt.year >= 2007)]\n",
        "\n",
        "def get_cpi(date):\n",
        "  for i in range(0, len(df_cpi)):\n",
        "\n",
        "    if date >= df_cpi['date'].iloc[i]:\n",
        "      last = df_cpi['value'].iloc[i]\n",
        "      continue\n",
        "    return last"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EgxhChjBLUCc",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "df_cci = pd.read_csv(\n",
        "    'https://raw.githubusercontent.com/rgumi/seminararbeit_src/master/refined/cci_monthly_ref.csv', \n",
        "    index_col=['index'], parse_dates=['date'])\n",
        "\n",
        "df_cci = df_cci[(df_cci['date'].dt.year >= 2007)]\n",
        "\n",
        "def get_cci(date):\n",
        "  for i in range(0, len(df_cci)):\n",
        "\n",
        "    if date >= df_cci['date'].iloc[i]:\n",
        "      last = df_cci['value'].iloc[i]\n",
        "      continue\n",
        "      \n",
        "    return last"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AYAngATPuYD4",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "ltz = {}\n",
        "with urllib.request.urlopen(\"https://raw.githubusercontent.com/rgumi/seminararbeit_src/master/refined/leitzinsen_eu.json\") as url:\n",
        "    tmp_ltz = json.loads(url.read().decode())\n",
        "for key in tmp_ltz.keys():\n",
        "  ltz[dt.datetime.strptime(key, '%d-%m-%Y')] = tmp_ltz[key]\n",
        "sorted_ltz = {k: ltz[k] for k in sorted(ltz)}\n",
        "\n",
        "def get_leitzins(date):\n",
        "  for key, val in sorted_ltz.items():\n",
        "    if date >= key:\n",
        "      last = val\n",
        "      continue\n",
        "    return last"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "f8rRxxjwEm-M",
        "colab_type": "code",
        "outputId": "a39982a1-0dfe-42c4-dedf-8eb74f694ab7",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 141
        }
      },
      "source": [
        "dataset = pd.read_csv(\n",
        "    'https://raw.githubusercontent.com/saschaschworm/big-data-and-data-science/master/datasets/prediction-challenge/dataset.csv', \n",
        "    index_col='identifier', parse_dates=['date'])\n",
        "\n",
        "dataset.insert(len(dataset.columns) -1, \"weekday\", dataset.date.dt.weekday)\n",
        "dataset.insert(len(dataset.columns) -1, \"day\", dataset.date.dt.day)\n",
        "dataset.insert(len(dataset.columns) -1, \"month\", dataset.date.dt.month)\n",
        "dataset.insert(len(dataset.columns) -1, \"year\", dataset.date.dt.year)\n",
        "dataset.insert(len(dataset.columns) -1, \"quarter\", dataset.date.dt.quarter)\n",
        "\n",
        "dataset.insert(len(dataset.columns)-1, \"leitzins\", dataset['date'].apply(get_leitzins))\n",
        "dataset.insert(len(dataset.columns)-1, \"euribor\", dataset['date'].apply(get_euribor))\n",
        "dataset.insert(len(dataset.columns)-1, \"cci\", dataset['date'].apply(get_cci))\n",
        "dataset.insert(len(dataset.columns)-1, \"cpi\", dataset['date'].apply(get_cpi))\n",
        "dataset.insert(len(dataset.columns)-1, \"fsi\", dataset['date'].apply(get_fsi))\n",
        "dataset.insert(len(dataset.columns)-1, \"eurostoxx\", dataset['date'].apply(get_eurostoxx))\n",
        "\n",
        "dataset = dataset.drop('date', axis=1)\n",
        "dataset.columns"
      ],
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Index(['age', 'marital_status', 'education', 'job', 'credit_default',\n",
              "       'housing_loan', 'personal_loan', 'communication_type',\n",
              "       'n_contacts_campaign', 'days_since_last_contact', 'n_contacts_before',\n",
              "       'previous_conversion', 'duration', 'weekday', 'day', 'month', 'year',\n",
              "       'quarter', 'leitzins', 'euribor', 'cci', 'cpi', 'fsi', 'eurostoxx',\n",
              "       'success'],\n",
              "      dtype='object')"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 10
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sAEYpvzPd7Wy",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def lineplot(df, column, title):\n",
        "  # get the count of each distinct values in series\n",
        "  value_counts = pd.DataFrame()\n",
        "  value_counts= df[column].value_counts()\n",
        "  value_counts_success = df[( df['success'] == 'Yes')].loc[:, column].value_counts()\n",
        "  # create a plot for the bar graph\n",
        "  _, axes = plt.subplots(2, 1, figsize=(20, 10))\n",
        "  sns.set_color_codes(\"pastel\")\n",
        "  sns.lineplot(value_counts.index, value_counts.values, color=\"b\",\n",
        "              label=\"Total\", ax=axes[0]) \n",
        "  \n",
        "  sns.set_color_codes(\"muted\")\n",
        "  sns.lineplot(value_counts_success.index, value_counts_success.values, color=\"b\",\n",
        "              label=\"Total\", ax=axes[0])\n",
        "  \n",
        "  axes[0].legend(ncol=2, loc=\"upper right\", frameon=True)\n",
        "  axes[0].set_title(title)\n",
        "\n",
        "  sns.boxplot(dataset[column], ax=axes[1],\n",
        "              flierprops = dict(markerfacecolor = '0.50', markersize = 2))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "93ZjmJmlQRWW",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def barboxplot(df, column, title):\n",
        "  '''\n",
        "    creates a barplot for the given data in df[column]\n",
        "    -> shows the dustribution the successrate of the given data\n",
        "    createa s boxplot for the given data in df[column]\n",
        "  '''\n",
        "  # get the count of each distinct values in series\n",
        "  value_counts = pd.DataFrame()\n",
        "  value_counts= df[column].value_counts()\n",
        "  value_counts_success = df[( df['success'] == 'Yes')].loc[:, column].value_counts()\n",
        "  # create a plot for the bar graph\n",
        "  _, axes = plt.subplots(2, 1, figsize=(20, 10))\n",
        "\n",
        "  sns.set_color_codes(\"pastel\")\n",
        "  sns.barplot(value_counts.index, value_counts.values, color=\"b\",\n",
        "              label=\"Total\", ax=axes[0])\n",
        "\n",
        "  sns.set_color_codes(\"muted\")\n",
        "  sns.barplot(value_counts_success.index, value_counts_success.values,\n",
        "              color=\"b\", label=\"Successful\", ax=axes[0])\n",
        "  \n",
        "\n",
        "  axes[0].legend(ncol=2, loc=\"upper right\", frameon=True)\n",
        "  axes[0].set_title(title)\n",
        "\n",
        "  sns.boxplot(dataset[column], ax=axes[1],\n",
        "              flierprops = dict(markerfacecolor = '0.50', markersize = 2))\n",
        "\n",
        "def barplot(df, column, title, axes):\n",
        "  '''\n",
        "    creates a barplot for the given data in df[column]\n",
        "    -> shows the dustribution the successrate of the given data\n",
        "    createa s boxplot for the given data in df[column]\n",
        "  '''\n",
        "  # get the count of each distinct values in series\n",
        "  value_counts = pd.DataFrame()\n",
        "  value_counts= df.loc[:, column].value_counts()\n",
        "  value_counts_success = df[( df['success'] == 'Yes')].loc[:, column].value_counts()\n",
        "  # create a plot for the bar graph\n",
        "\n",
        "\n",
        "  sns.set_color_codes(\"pastel\")\n",
        "  sns.barplot(value_counts.index, value_counts.values, color=\"b\",\n",
        "              label=\"Total\", ax=axes)\n",
        "\n",
        "  sns.set_color_codes(\"muted\")\n",
        "  sns.barplot(value_counts_success.index, value_counts_success.values,\n",
        "              color=\"b\", label=\"Successful\", ax=axes)\n",
        "  \n",
        "\n",
        "  axes.legend(ncol=2, loc=\"upper right\", frameon=True)\n",
        "  axes.set_title(title) \n",
        "\n",
        "barboxplot(dataset, 'age', 'Age Distribution')\n",
        "\n",
        "\n",
        "_, axes = plt.subplots(2, 2, figsize=(20, 20))\n",
        "\n",
        "counter = 0\n",
        "for item in ['marital_status', 'job', 'education', 'previous_conversion']:\n",
        "  trace_x = counter // 2\n",
        "  trace_y = counter % 2\n",
        "\n",
        "  barplot(dataset, item, item + ' Distribution', axes[trace_x, trace_y])\n",
        "  \n",
        "  counter += 1"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "chldv7-yEP04",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "X, y = dataset[['month', 'education', 'job', 'age', 'previous_conversion', 'n_contacts_before',\n",
        "       'days_since_last_contact', 'leitzins', 'euribor', 'n_contacts_campaign', 'marital_status',\n",
        "       'credit_default', 'duration', 'housing_loan', 'cpi', 'cci', 'eurostoxx', 'fsi',\n",
        "       'personal_loan']], dataset['success']\n",
        "y = y.apply(lambda x: 1 if x == \"Yes\" else 0)\n",
        "\n",
        "#X = X[(X['job'] != 'Unknown')]\n",
        "\n",
        "#X['education'] = X['education'].apply(group_education)\n",
        "#X['job'] = X['job'].apply(group_job)\n",
        "X['previous_conversion'] = X['previous_conversion'].apply(group_p_conv)\n",
        "#X['marital_status'] = X['marital_status'].apply(group_martial_status)\n",
        "# X['age'] = X['age'].apply(group_age_q) # group_age_q == quantile\n",
        "# X['duration'] = X['duration'].apply(group_duration)\n",
        "\n",
        "for item in ['education', 'job', 'previous_conversion',\n",
        "             'credit_default', 'housing_loan', \n",
        "             'education', 'marital_status', 'personal_loan']:\n",
        "  try:\n",
        "    encoded = pd.get_dummies(X[item], prefix=item)\n",
        "    X.drop(item, axis=1, inplace=True)\n",
        "    X = X.join(encoded)\n",
        "  except:\n",
        "    continue\n",
        "\n",
        "scaler = MinMaxScaler()\n",
        "numeric_values = [\"leitzins\", \"euribor\", 'cpi', 'cci', 'n_contacts_campaign',\n",
        "                  'n_contacts_before', 'duration', 'days_since_last_contact',\n",
        "                  'eurostoxx', 'fsi', 'age']\n",
        "\n",
        "X[numeric_values] = scaler.fit_transform(X[numeric_values])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZaCVpn7rKTRQ",
        "colab_type": "text"
      },
      "source": [
        "# Model Comparison\n",
        "\n",
        "The objective of this model is to predict a binary classification. Therefore only models that support binary classificiation are compared. The models are:\n",
        "1. Logistic Regression (`sklearn.linear_model SGDClassifier`)\n",
        "2. Decision Tree: Random Forests(`sklearn.ensemble RandomForestClassifier` & `xgboost XGBRFClassifier`)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fqp5FfOwSbEi",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.4, random_state = 1909)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9FfcrQEoSH6K",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def evaluate_model(model):\n",
        "  print(f'Model: {str(model).split(\"(\")[0]}\\n')\n",
        "  res_cv = cross_validate(model, X, y, scoring=['f1'], cv=10, return_train_score=True)\n",
        "  res_f1_tr = np.mean(res_cv['train_f1']) * 100\n",
        "  res_f1_te = np.mean(res_cv['test_f1']) * 100\n",
        "  print(f'Average F1 on Training and Test Set: {res_f1_tr:.2f}%/{res_f1_te:.2f}%')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "al7QLzw9KSrY",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from sklearn.linear_model import SGDClassifier\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from xgboost import XGBClassifier, XGBRFClassifier\n",
        "\n",
        "\n",
        "sk_classifier = SGDClassifier()\n",
        "#print(f'parameters (sk_classifier):\\n{sk_classifier}')\n",
        "evaluate_model(SGDClassifier())\n",
        "sk_classifier.fit(X_train, y_train)\n",
        "sk_classifier_pred = sk_classifier.predict(X_test)\n",
        "print(classification_report(sk_classifier_pred, y_test))\n",
        "print(confusion_matrix(y_test, sk_classifier_pred))\n",
        "print('---\\n')\n",
        "\n",
        "sk_rf_classifier = RandomForestClassifier()\n",
        "#print(f'parameters (sk_rf_classifier):\\n{sk_rf_classifier}')\n",
        "evaluate_model(RandomForestClassifier())\n",
        "sk_rf_classifier.fit(X_train, y_train)\n",
        "sk_rf_classifier_pred = sk_rf_classifier.predict(X_test)\n",
        "print(classification_report(sk_rf_classifier_pred, y_test))\n",
        "print(confusion_matrix(y_test, sk_rf_classifier_pred))\n",
        "print('---\\n')\n",
        "\n",
        "xg_classifier = XGBClassifier()\n",
        "#print(f'parameters (xg_classifier):\\n{xg_classifier}')\n",
        "evaluate_model(XGBClassifier())\n",
        "xg_classifier.fit(X_train, y_train)\n",
        "xg_classifier_pred = xg_classifier.predict(X_test)\n",
        "print(classification_report(xg_classifier_pred, y_test))\n",
        "print(confusion_matrix(y_test, xg_classifier_pred))\n",
        "print('---\\n')\n",
        "\n",
        "xg_rf_classifier = XGBRFClassifier()\n",
        "#print(f'parameters (xg_rf_classifier):\\n{xg_rf_classifier}')\n",
        "evaluate_model(XGBRFClassifier())\n",
        "xg_rf_classifier.fit(X_train, y_train)\n",
        "xg_rf_classifier_pred = xg_rf_classifier.predict(X_test)\n",
        "print(classification_report(xg_rf_classifier_pred, y_test))\n",
        "print(confusion_matrix(y_test, xg_rf_classifier_pred))\n",
        "print('---\\n')\n",
        "\n",
        "\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SaWaBHj84ERk",
        "colab_type": "text"
      },
      "source": [
        "# Model Selection\n",
        "\n",
        "Based on the previous evaluation the models chosen to be futher evaluated are:\n",
        "1. XGBClassfier\n",
        "2. XGBRFClassifier"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6P7d4DFsXiyB",
        "colab_type": "text"
      },
      "source": [
        "# Hyperparameter optimization"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "L1cXNmVcZ5KR",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "custom_scorer = make_scorer(f1_score)\n",
        "\n",
        "# randomized hyperparameter optimization\n",
        "# https://www.analyticsvidhya.com/blog/2016/03/complete-guide-parameter-tuning-xgboost-with-codes-python/\n",
        "def optimization(model):\n",
        "  print(f'Model: {str(model).split(\"(\")[0]}\\n')\n",
        "  ## default is 3\n",
        "  n_estimators = randint(2, 20)\n",
        "  ## default is 100\n",
        "  max_depth = randint(80, 120)\n",
        "  ## default is 0.1 and 1 respectively\n",
        "  learning_rate = uniform()\n",
        "\n",
        "  # Sampling\n",
        "  ## default is 1\n",
        "  colsample_bytree = uniform()\n",
        "  ## default is 1\n",
        "  colsample_bylevel = uniform()\n",
        "  ## default is 1\n",
        "  colsample_bynode = uniform()\n",
        "\n",
        "  # default is 1\n",
        "  min_child_weight = uniform()\n",
        "\n",
        "\n",
        "  gamma = uniform()\n",
        "  base_score = uniform()\n",
        "  subsample = uniform()\n",
        "\n",
        "  # default is 10, changed to 9 due to \n",
        "  scale_pos_weight = 9\n",
        "  reg_lambda = 1\n",
        "\n",
        "  # optimization parameters\n",
        "  param_distributions = {'model__n_estimators': n_estimators,\n",
        "                         'model__max_depth': max_depth,\n",
        "                         \n",
        "                         #'model__learning_rate': learning_rate,\n",
        "                         #'model__gamma': gamma,\n",
        "                         #'model__min_child_weight': min_child_weight,\n",
        "                         #'model__base_score': base_score,\n",
        "                         #'model__subsample': subsample,\n",
        "                         #'model__colsample_bylevel': colsample_bylevel,\n",
        "                         #'model__colsample_bytree': colsample_bytree,\n",
        "                         #'model__colsample_bynode': colsample_bynode,\n",
        "                        }\n",
        "\n",
        "  rs = RandomizedSearchCV(model, param_distributions=param_distributions, n_iter=5,\n",
        "                        scoring=custom_scorer, n_jobs=-1, cv=10, random_state=1909)\n",
        "  rs_result = rs.fit(X, y)\n",
        "  return rs_result.best_params_"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "023_1lMnPCtg",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 123
        },
        "outputId": "72efa374-a333-4067-b120-98f4a2d19480"
      },
      "source": [
        "from xgboost import XGBClassifier, XGBRFClassifier\n",
        "\n",
        "xg_classifier = XGBClassifier()\n",
        "#print(f'parameters (xg_classifier):\\n{xg_classifier}')\n",
        "xg_classifier_params = optimization(xg_classifier)\n",
        "print(xg_classifier_params)\n",
        "\n",
        "\n",
        "\n",
        "xg_rf_classifier = XGBRFClassifier()\n",
        "#print(f'parameters (xg_rf_classifier):\\n{xg_rf_classifier}')\n",
        "xg_rf_classifier_params = optimization(xg_rf_classifier)\n",
        "print(xg_rf_classifier_params)"
      ],
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: XGBClassifier\n",
            "\n",
            "{'model__max_depth': 94, 'model__n_estimators': 11}\n",
            "Model: XGBRFClassifier\n",
            "\n",
            "{'model__max_depth': 94, 'model__n_estimators': 11}\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "AzzGIcPscnZL",
        "colab_type": "text"
      },
      "source": [
        "# Evaluating Model with Optimized Parameter"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "s5C8ncl1bttg",
        "colab_type": "code",
        "outputId": "8e1b2a4c-e054-4158-94c2-a34e6981a8a7",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 123
        }
      },
      "source": [
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.4, random_state = 1909)\n",
        "\n",
        "hyperparams = {'seed': 1909,\n",
        "               'nthread': -1,\n",
        "               'objective': 'binary:logistic',\n",
        "               'silent': True,\n",
        "               'reg_lambda': 1,\n",
        "               'missing': None,\n",
        "               'max_delta_step': 0,\n",
        "               'n_estimators': 94,\n",
        "               'max_deph': 11,\n",
        "               }\n",
        "\n",
        "xg_classifier = XGBClassifier(**hyperparams)\n",
        "evaluate_model(xg_classifier)\n",
        "xg_rf_classifier = XGBRFClassifier(**hyperparams)\n",
        "evaluate_model(xg_rf_classifier)"
      ],
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: XGBClassifier\n",
            "\n",
            "Average F1 on Training and Test Set: 58.34%/56.89%\n",
            "Model: XGBRFClassifier\n",
            "\n",
            "Average F1 on Training and Test Set: 58.31%/57.91%\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hw70SnSgfRPB",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# persists results for later analysis\n",
        "\n",
        "resultJSON = {\n",
        "    \"date\": dt.datetime.now().strftime(\"%d.%m.%Y, %H:%M:%S\"),\n",
        "    \"result\": f'{XGB:.2f}',\n",
        "    \"hyperparams\": hyperparams\n",
        "}\n",
        "\n",
        "with open(mountpath + '/My Drive/seminararbeit/results-feb-v3.txt', 'a') as file:\n",
        "  file.write(str(resultJSON) + '\\n')"
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}
{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "feb-v4.ipynb",
      "provenance": [],
      "toc_visible": true,
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/rgumi/seminararbeit_src/blob/master/feb_v4.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oIo03i7VErog",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from scipy.stats import randint, uniform\n",
        "import datetime as dt\n",
        "import numpy as np\n",
        "import pandas as pd \n",
        "import json\n",
        "import urllib.request\n",
        "pd.options.mode.chained_assignment = None\n",
        "\n",
        "from sklearn.model_selection import train_test_split, cross_validate, RandomizedSearchCV, cross_val_score\n",
        "from sklearn.metrics import f1_score, make_scorer, confusion_matrix, accuracy_score, classification_report\n",
        "from sklearn.linear_model import LogisticRegression, SGDClassifier\n",
        "from sklearn.preprocessing import MinMaxScaler\n",
        "from xgboost.sklearn import XGBClassifier\n",
        "from xgboost import XGBRFClassifier\n",
        "\n",
        "import seaborn as sns\n",
        "import matplotlib.pyplot as plt\n",
        "sns.set(style=\"whitegrid\")"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JehFQQjKxDPF",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "mountpath = \"/content/drive\"\n",
        "from google.colab import drive\n",
        "drive.mount(mountpath)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "65g0sBlAx75d",
        "colab_type": "text"
      },
      "source": [
        "# Data Preprocessing\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "s-KcWWVQyMMk",
        "colab_type": "text"
      },
      "source": [
        "## Transformation"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "V9rsfxVlpc1u",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# ['High School', 'University', 'Middle School', 'Professional Training', \n",
        "# 'Elementary School', 'Unknown', 'Illiterate']\n",
        "\n",
        "def group_education(education):\n",
        "  if education in ['Elementary School']:\n",
        "    return 'primary'\n",
        "  if education in ['Middle School', 'High School']:\n",
        "    return 'secondary'\n",
        "  if education in ['University', 'Professional Training']:\n",
        "    return 'tertiary'\n",
        "  return 'unknown'\n",
        "\n",
        "# ['Service provider', 'Student', 'Pensioner', 'Administrator', 'Technician',\n",
        "# 'Blue-collar worker', 'Self-employed', 'Unemployed', 'Manager', 'Housemaid', 'Founder', 'Unknown']\n",
        "\n",
        "def group_job(job):\n",
        "  if job in ['Service provider', 'Housemaid']:\n",
        "    return 'pink-collar worker'\n",
        "  if job in ['Blue-collar worker']:\n",
        "    return 'blue-collar worker'\n",
        "  if job in ['Administrator', 'Manager']:\n",
        "    return 'white-collar worker'\n",
        "  if job in ['Self-employed', 'Founder']:\n",
        "    return 'independent'\n",
        "  return str.lower(job)\n",
        "\n",
        "def group_p_conv(pconv):\n",
        "  if pconv == 'Successful':\n",
        "    return 1\n",
        "  if pconv == 'Failed':\n",
        "    return 2\n",
        "  return 3\n",
        "\n",
        "def group_age(age):\n",
        "  if age < 29:\n",
        "    return 2\n",
        "  if age < 59:\n",
        "    return 3\n",
        "  return 1\n",
        "\n",
        "def group_age_q(age):\n",
        "  if age < 30:\n",
        "    return 1\n",
        "  if age < 35:\n",
        "    return 2\n",
        "  if age < 42:\n",
        "    return 3\n",
        "  if age < 49:\n",
        "    return 4\n",
        "  return 5\n",
        "  \n",
        "def group_duration(duration):\n",
        "  if duration == 0:\n",
        "    return 5\n",
        "  if duration < 60:\n",
        "    return 4\n",
        "  if duration < 300:\n",
        "    return 3\n",
        "  if duration < 600:\n",
        "    return 2\n",
        "  return 1\n",
        "\n",
        "def group_martial_status(status):\n",
        "  if status == 'single':\n",
        "    return 1\n",
        "  if status == 'married':\n",
        "    return 2\n",
        "  if status == 'divorced':\n",
        "    return 3\n",
        "  return 4\n",
        "\n",
        "def replace_loan(loan):\n",
        "  if loan == 'Unknown':\n",
        "    return 1\n",
        "  if loan == 'No':\n",
        "    return 2\n",
        "  if loan == 'Yes':\n",
        "    return 3"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "m8UHa8-ZyA22",
        "colab_type": "text"
      },
      "source": [
        "## Feature Additions"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hjf8i_m7vd3C",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "df_euribor = pd.read_csv(\n",
        "    'https://raw.githubusercontent.com/rgumi/seminararbeit_src/master/refined/euribor3m_ref.csv', \n",
        "    index_col=['index'], parse_dates=['date'])\n",
        "\n",
        "df_euribor = df_euribor[(df_euribor['date'].dt.year >= 2007)]\n",
        "\n",
        "def get_euribor(date):\n",
        "  for i in range(0, len(df_euribor)):\n",
        "\n",
        "    if date >= df_euribor['date'].iloc[i]:\n",
        "      last = df_euribor['value'].iloc[i]\n",
        "      continue\n",
        "    return round(last, 2)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8a8uQAdvOVte",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "df_eurostoxx= pd.read_csv(\n",
        "    'https://raw.githubusercontent.com/rgumi/seminararbeit_src/master/refined/eurostoxx_ref.csv', \n",
        "    index_col=['index'], parse_dates=['date'])\n",
        "\n",
        "df_eurostoxx = df_eurostoxx[(df_eurostoxx['date'].dt.year >= 2007)]\n",
        "\n",
        "def get_eurostoxx(date):\n",
        "  for i in range(0, len(df_eurostoxx)):\n",
        "\n",
        "    if date >= df_eurostoxx['date'].iloc[i]:\n",
        "      last = df_eurostoxx['value'].iloc[i]\n",
        "      continue\n",
        "    return last"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JS4n-_a4OgdJ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "df_fsi= pd.read_csv(\n",
        "    'https://raw.githubusercontent.com/rgumi/seminararbeit_src/master/refined/fsi_ref.csv', \n",
        "    index_col=['index'], parse_dates=['Date'])\n",
        "\n",
        "df_fsi = df_fsi[(df_fsi['Date'].dt.year >= 2007)]\n",
        "\n",
        "def get_fsi(date):\n",
        "  for i in range(0, len(df_fsi)):\n",
        "\n",
        "    if date >= df_fsi['Date'].iloc[i]:\n",
        "      # Possible values: [OFR FSI, Credit, Equity valuation, Safe assets, Funding, Volatility]\n",
        "      last = df_fsi['OFR FSI'].iloc[i]\n",
        "      continue\n",
        "    return last"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "33cyR0R7Llxb",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "df_cpi = pd.read_csv(\n",
        "    'https://raw.githubusercontent.com/rgumi/seminararbeit_src/master/refined/cpi_monthly_ref.csv', \n",
        "    index_col=['index'], parse_dates=['date'])\n",
        "\n",
        "df_cpi = df_cpi[(df_cpi['date'].dt.year >= 2007)]\n",
        "\n",
        "def get_cpi(date):\n",
        "  for i in range(0, len(df_cpi)):\n",
        "\n",
        "    if date >= df_cpi['date'].iloc[i]:\n",
        "      last = df_cpi['value'].iloc[i]\n",
        "      continue\n",
        "    return last"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EgxhChjBLUCc",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "df_cci = pd.read_csv(\n",
        "    'https://raw.githubusercontent.com/rgumi/seminararbeit_src/master/refined/cci_monthly_ref.csv', \n",
        "    index_col=['index'], parse_dates=['date'])\n",
        "\n",
        "df_cci = df_cci[(df_cci['date'].dt.year >= 2007)]\n",
        "\n",
        "def get_cci(date):\n",
        "  for i in range(0, len(df_cci)):\n",
        "\n",
        "    if date >= df_cci['date'].iloc[i]:\n",
        "      last = df_cci['value'].iloc[i]\n",
        "      continue\n",
        "      \n",
        "    return last"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AYAngATPuYD4",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "ltz = {}\n",
        "with urllib.request.urlopen(\"https://raw.githubusercontent.com/rgumi/seminararbeit_src/master/refined/leitzinsen_eu.json\") as url:\n",
        "    tmp_ltz = json.loads(url.read().decode())\n",
        "for key in tmp_ltz.keys():\n",
        "  ltz[dt.datetime.strptime(key, '%d-%m-%Y')] = tmp_ltz[key]\n",
        "sorted_ltz = {k: ltz[k] for k in sorted(ltz)}\n",
        "\n",
        "def get_leitzins(date):\n",
        "  for key, val in sorted_ltz.items():\n",
        "    if date >= key:\n",
        "      last = val\n",
        "      continue\n",
        "    return last"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "G1XyhparyOOd",
        "colab_type": "text"
      },
      "source": [
        "# Visualization"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sAEYpvzPd7Wy",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def lineplot(df, column, title):\n",
        "  # get the count of each distinct values in series\n",
        "  value_counts = pd.DataFrame()\n",
        "  value_counts= df[column].value_counts()\n",
        "  value_counts_success = df[( df['success'] == 'Yes')].loc[:, column].value_counts()\n",
        "  # create a plot for the bar graph\n",
        "  _, axes = plt.subplots(2, 1, figsize=(20, 10))\n",
        "  sns.set_color_codes(\"pastel\")\n",
        "  sns.lineplot(value_counts.index, value_counts.values, color=\"b\",\n",
        "              label=\"Total\", ax=axes[0]) \n",
        "  \n",
        "  sns.set_color_codes(\"muted\")\n",
        "  sns.lineplot(value_counts_success.index, value_counts_success.values, color=\"b\",\n",
        "              label=\"Total\", ax=axes[0])\n",
        "  \n",
        "  axes[0].legend(ncol=2, loc=\"upper right\", frameon=True)\n",
        "  axes[0].set_title(title)\n",
        "\n",
        "  sns.boxplot(dataset[column], ax=axes[1],\n",
        "              flierprops = dict(markerfacecolor = '0.50', markersize = 2))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "93ZjmJmlQRWW",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def barboxplot(df, column, title):\n",
        "  '''\n",
        "    creates a barplot for the given data in df[column]\n",
        "    -> shows the distribution the successrate of the given data\n",
        "    createa s boxplot for the given data in df[column]\n",
        "  '''\n",
        "  # get the count of each distinct values in series\n",
        "  value_counts = pd.DataFrame()\n",
        "  value_counts= df[column].value_counts()\n",
        "  value_counts_success = df[( df['success'] == 'Yes')].loc[:, column].value_counts()\n",
        "  # create a plot for the bar graph\n",
        "  _, axes = plt.subplots(2, 1, figsize=(20, 10))\n",
        "\n",
        "  sns.set_color_codes(\"pastel\")\n",
        "  sns.barplot(value_counts.index, value_counts.values, color=\"b\",\n",
        "              label=\"Total\", ax=axes[0])\n",
        "\n",
        "  sns.set_color_codes(\"muted\")\n",
        "  sns.barplot(value_counts_success.index, value_counts_success.values,\n",
        "              color=\"b\", label=\"Successful\", ax=axes[0])\n",
        "  \n",
        "\n",
        "  axes[0].legend(ncol=2, loc=\"upper right\", frameon=True)\n",
        "  axes[0].set_title(title)\n",
        "\n",
        "  sns.boxplot(dataset[column], ax=axes[1],\n",
        "              flierprops = dict(markerfacecolor = '0.50', markersize = 2))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tP1lNpKC1SHx",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def barplot(df, column, title):\n",
        "  '''\n",
        "    creates a barplot for the given data in df[column]\n",
        "    -> shows the distribution the successrate of the given data\n",
        "  '''\n",
        "  _, axes = plt.subplots(1, 1, figsize=(20, 10))\n",
        "  # get the count of each distinct values in series\n",
        "  value_counts = pd.DataFrame()\n",
        "  value_counts= df.loc[:, column].value_counts()\n",
        "  value_counts_success = df[( df['success'] == 'Yes')].loc[:, column].value_counts()\n",
        "  # create a plot for the bar graph\n",
        "\n",
        "\n",
        "  sns.set_color_codes(\"pastel\")\n",
        "  sns.barplot(value_counts.index, value_counts.values, color=\"b\",\n",
        "              label=\"Total\", ax=axes)\n",
        "\n",
        "  sns.set_color_codes(\"muted\")\n",
        "  sns.barplot(value_counts_success.index, value_counts_success.values,\n",
        "              color=\"b\", label=\"Successful\", ax=axes)\n",
        "  \n",
        "\n",
        "  axes.legend(ncol=2, loc=\"upper right\", frameon=True)\n",
        "  axes.set_title(title)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "l0IQ5mkTyTBt",
        "colab_type": "text"
      },
      "source": [
        "# Pipeline"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "f8rRxxjwEm-M",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 119
        },
        "outputId": "a04e534a-7e2c-4d16-b584-5c23bd8741dd"
      },
      "source": [
        "dataset = pd.read_csv(\n",
        "    'https://raw.githubusercontent.com/saschaschworm/big-data-and-data-science/master/datasets/prediction-challenge/dataset.csv', \n",
        "    index_col='identifier', parse_dates=['date'])\n",
        "\n",
        "dataset.insert(len(dataset.columns) -1, \"weekday\", dataset.date.dt.weekday)\n",
        "dataset.insert(len(dataset.columns) -1, \"day\", dataset.date.dt.day)\n",
        "dataset.insert(len(dataset.columns) -1, \"month\", dataset.date.dt.month)\n",
        "dataset.insert(len(dataset.columns) -1, \"year\", dataset.date.dt.year)\n",
        "dataset.insert(len(dataset.columns) -1, \"quarter\", dataset.date.dt.quarter)\n",
        "\n",
        "#dataset.insert(len(dataset.columns)-1, \"leitzins\", dataset['date'].apply(get_leitzins))\n",
        "dataset.insert(len(dataset.columns)-1, \"euribor\", dataset['date'].apply(get_euribor))\n",
        "#dataset.insert(len(dataset.columns)-1, \"cci\", dataset['date'].apply(get_cci))\n",
        "dataset.insert(len(dataset.columns)-1, \"cpi\", dataset['date'].apply(get_cpi))\n",
        "#dataset.insert(len(dataset.columns)-1, \"fsi\", dataset['date'].apply(get_fsi))\n",
        "#dataset.insert(len(dataset.columns)-1, \"eurostoxx\", dataset['date'].apply(get_eurostoxx))\n",
        "\n",
        "dataset = dataset.drop('date', axis=1)\n",
        "dataset.columns\n"
      ],
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Index(['age', 'marital_status', 'education', 'job', 'credit_default',\n",
              "       'housing_loan', 'personal_loan', 'communication_type',\n",
              "       'n_contacts_campaign', 'days_since_last_contact', 'n_contacts_before',\n",
              "       'previous_conversion', 'duration', 'weekday', 'day', 'month', 'year',\n",
              "       'quarter', 'euribor', 'cpi', 'success'],\n",
              "      dtype='object')"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 12
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fEX1qCkYmsQM",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "numerical_features = ['n_contacts_campaign', 'days_since_last_contact', 'age', 'euribor', 'cpi']\n",
        "for item in numerical_features:\n",
        "  barboxplot(dataset, item, item + ' distribution')\n",
        "  plt.savefig(mountpath + '/My Drive/seminararbeit/images/numerical_features/' + item + '.png')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MRBfFx2eufqG",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "for item in ['n_contacts_before', 'duration']:\n",
        "  print(dataset[item].unique())\n",
        "  print(dataset[item].quantile(.95))\n",
        "  sns.boxplot(dataset[item],\n",
        "              flierprops = dict(markerfacecolor = '0.50', markersize = 2))\n",
        "  plt.savefig(mountpath + '/My Drive/seminararbeit/images/numerical_features/' + item + '.png')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gG0XLxc0wrW4",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "categorical_features = ['education', 'job', 'previous_conversion',\n",
        "                        'credit_default', 'housing_loan', 'month',\n",
        "                        'education', 'marital_status', 'personal_loan']\n",
        "\n",
        "for item in categorical_features:\n",
        "  barplot(dataset, item, item + ' distribution')\n",
        "  plt.savefig(mountpath + '/My Drive/seminararbeit/images/categorical_features/' + item + '.png')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1xZlmA_plmfX",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# drop some rows\n",
        "#dataset = dataset[ dataset.duration <= 756 ]\n",
        "#\n",
        "#sns.boxplot(dataset['duration'],\n",
        "#              flierprops = dict(markerfacecolor = '0.50', markersize = 2))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "chldv7-yEP04",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "X = dataset[['month', 'education', 'job', 'age', 'previous_conversion', 'n_contacts_before',\n",
        "       'days_since_last_contact', 'n_contacts_campaign', 'marital_status', 'credit_default',\n",
        "       'duration', 'housing_loan', 'personal_loan',\n",
        "       'euribor', 'cpi']]\n",
        "       \n",
        "y = dataset['success']\n",
        "y = y.apply(lambda x: 1 if x == \"Yes\" else 0)\n",
        "\n",
        "\n",
        "\n",
        "#X['education'] = X['education'].apply(group_education)\n",
        "#X['job'] = X['job'].apply(group_job)\n",
        "#X['previous_conversion'] = X['previous_conversion'].apply(group_p_conv)\n",
        "#X['marital_status'] = X['marital_status'].apply(group_martial_status)\n",
        "# X['age'] = X['age'].apply(group_age_q) # group_age_q == quantile\n",
        "# X['duration'] = X['duration'].apply(group_duration)\n",
        "X['credit_default'] = X['credit_default'].apply(replace_loan)\n",
        "X['personal_loan'] = X['personal_loan'].apply(replace_loan)\n",
        "X['housing_loan'] = X['housing_loan'].apply(replace_loan)\n",
        "\n",
        "\n",
        "categorical_features = ['education', 'job', 'previous_conversion',\n",
        "                        'marital_status']\n",
        "\n",
        "for item in categorical_features:\n",
        "  try:\n",
        "    encoded = pd.get_dummies(X[item], prefix=item)\n",
        "    X.drop(item, axis=1, inplace=True)\n",
        "    X = X.join(encoded)\n",
        "  except Exception as e:\n",
        "    print(\"Something went wrong?!\")\n",
        "    print(e)\n",
        "    continue\n",
        "\n",
        "scaler = MinMaxScaler()\n",
        "numerical_features = ['n_contacts_campaign', 'duration', \n",
        "                  'days_since_last_contact', 'age',\n",
        "                  'euribor', 'cpi']\n",
        "\n",
        "\n",
        "X[numerical_features] = scaler.fit_transform(X[numerical_features])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZaCVpn7rKTRQ",
        "colab_type": "text"
      },
      "source": [
        "# Model Comparison\n",
        "\n",
        "The objective of this model is to predict a binary classification. Therefore only models that support binary classificiation are compared. The models are:\n",
        "1. Logistic Regression (`sklearn.linear_model SGDClassifier`)\n",
        "2. Decision Tree: Random Forests(`sklearn.ensemble RandomForestClassifier` & `xgboost XGBRFClassifier`)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9FfcrQEoSH6K",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "all_results = []\n",
        "results = {}\n",
        "def evaluate_model(model):\n",
        "  model_name = f'Model: {str(model).split(\"(\")[0]}'\n",
        "  print(model_name)\n",
        "  res_cv = cross_validate(model, X, y, scoring=['f1'], cv=10, return_train_score=True)\n",
        "  res_f1_tr = np.mean(res_cv['train_f1']) * 100\n",
        "  res_f1_te = np.mean(res_cv['test_f1']) * 100\n",
        "  model_result = f'{res_f1_tr:.2f}%/{res_f1_te:.2f}%'\n",
        "  results[model_name] = model_result\n",
        "  print(f'Average F1 on Training and Test Set: {res_f1_tr:.2f}%/{res_f1_te:.2f}%\\n')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HdjjDelcxTZq",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.4, random_state = 1909)\n",
        "def evaluate_model_splitted(model):\n",
        "  model.fit(X_train, y_train)\n",
        "  model_pred = model.predict(X_test)\n",
        "  print(classification_report(model_pred, y_test))\n",
        "  print(confusion_matrix(y_test, model_pred))\n",
        "  print('---\\n') "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "al7QLzw9KSrY",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from sklearn.linear_model import SGDClassifier\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from xgboost import XGBClassifier, XGBRFClassifier\n",
        "\n",
        "\n",
        "evaluate_model(SGDClassifier())\n",
        "evaluate_model_splitted(SGDClassifier())\n",
        "\n",
        "evaluate_model(RandomForestClassifier())\n",
        "evaluate_model_splitted(RandomForestClassifier())\n",
        "\n",
        "evaluate_model(XGBClassifier())\n",
        "evaluate_model_splitted(XGBClassifier())\n",
        "\n",
        "evaluate_model(XGBRFClassifier())\n",
        "evaluate_model_splitted((XGBRFClassifier()))\n",
        "\n",
        "all_results.append(results)\n",
        "print(all_results)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SaWaBHj84ERk",
        "colab_type": "text"
      },
      "source": [
        "# Model Selection\n",
        "\n",
        "Based on the previous evaluation the models chosen to be futher evaluated are:\n",
        "1. XGBClassfier\n",
        "2. XGBRFClassifier"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6P7d4DFsXiyB",
        "colab_type": "text"
      },
      "source": [
        "# Hyperparameter optimization"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "L1cXNmVcZ5KR",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "custom_scorer = make_scorer(f1_score)\n",
        "\n",
        "# randomized hyperparameter optimization\n",
        "# https://www.analyticsvidhya.com/blog/2016/03/complete-guide-parameter-tuning-xgboost-with-codes-python/\n",
        "def optimization(model):\n",
        "  print(f'Model: {str(model)}')\n",
        "  ## default is 3\n",
        "  n_estimators = randint(2, 20)\n",
        "  ## default is 100\n",
        "  max_depth = randint(80, 120)\n",
        "  ## default is 0.1 and 1 respectively\n",
        "  learning_rate = uniform()\n",
        "\n",
        "  # Sampling\n",
        "  ## default is 1\n",
        "  colsample_bytree = uniform()\n",
        "  ## default is 1\n",
        "  colsample_bylevel = uniform()\n",
        "  ## default is 1\n",
        "  colsample_bynode = uniform()\n",
        "\n",
        "  # default is 1\n",
        "  min_child_weight = uniform()\n",
        "\n",
        "\n",
        "  gamma = uniform()\n",
        "  base_score = uniform()\n",
        "  subsample = uniform()\n",
        "\n",
        "  # optimization parameters\n",
        "  param_distributions = {#'model__n_estimators': n_estimators,\n",
        "                         #'model__max_depth': max_depth,\n",
        "                         #'model__learning_rate': learning_rate,\n",
        "                         #'model__gamma': gamma,\n",
        "                         #'model__min_child_weight': min_child_weight,\n",
        "                         #'model__base_score': base_score,\n",
        "                         'model__subsample': subsample,\n",
        "                         'model__colsample_bylevel': colsample_bylevel,\n",
        "                         'model__colsample_bytree': colsample_bytree,\n",
        "                         'model__colsample_bynode': colsample_bynode,\n",
        "                        }\n",
        "                        \n",
        "  search = RandomizedSearchCV(model, param_distributions=param_distributions, n_iter=5,\n",
        "                        scoring=custom_scorer, n_jobs=-1, cv=10, random_state=1909)\n",
        "  \n",
        "  search = search.fit(X, y)\n",
        "  return search.best_params_"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "023_1lMnPCtg",
        "colab_type": "code",
        "outputId": "e2e4e83a-6025-4daa-e3af-f94ea8665b28",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 153
        }
      },
      "source": [
        "from xgboost import XGBClassifier, XGBRFClassifier\n",
        "\n",
        "hyperparams = {'seed': 1909,\n",
        "                'nthread': -1,\n",
        "                'booster': 'gbtree',\n",
        "                'objective': 'binary:logistic',\n",
        "                'silent': True,\n",
        "                'reg_lambda': 1,\n",
        "                'missing': None,\n",
        "                'max_delta_step': 0,\n",
        "                'n_estimators': 94,\n",
        "                'max_deph': 11,\n",
        "                'gamma': 0,\n",
        "                'learning_rate': 0.3,\n",
        "                'base_score': 0.5,\n",
        "                'min_child_weight': 1,\n",
        "                'scale_pos_weight': 9,\n",
        "                'subsample': 1,\n",
        "                'colsample_bylevel': 1,\n",
        "                'colsample_bytree': 1,\n",
        "                'colsample_bynode': 1,\n",
        "                'reg_lambda': 1,\n",
        "              }\n",
        "\n",
        "xg_classifier = XGBClassifier(**hyperparams)\n",
        "#print(f'parameters (xg_classifier):\\n{xg_classifier}')\n",
        "xg_classifier_params = optimization(xg_classifier)\n",
        "print(xg_classifier_params)\n"
      ],
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: XGBClassifier(base_score=0.5, booster='gbtree', colsample_bylevel=1,\n",
            "              colsample_bynode=1, colsample_bytree=1, gamma=0,\n",
            "              learning_rate=0.3, max_delta_step=0, max_deph=11, max_depth=3,\n",
            "              min_child_weight=1, missing=None, n_estimators=94, n_jobs=1,\n",
            "              nthread=-1, objective='binary:logistic', random_state=0,\n",
            "              reg_alpha=0, reg_lambda=1, scale_pos_weight=9, seed=1909,\n",
            "              silent=True, subsample=1, verbosity=1)\n",
            "{'model__colsample_bylevel': 0.6699737886943773, 'model__colsample_bynode': 0.08615916646337052, 'model__colsample_bytree': 0.5493585594031315, 'model__subsample': 0.5115457995342926}\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "i5I6rhGnuJzc",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 153
        },
        "outputId": "c1cd2774-13c0-45f4-efe5-5e7416ab665c"
      },
      "source": [
        "hyperparams = {'seed': 1909,\n",
        "                'nthread': -1,\n",
        "                'objective': 'binary:logistic',\n",
        "                'silent': True,\n",
        "                'reg_lambda': 1,\n",
        "                'missing': None,\n",
        "                'max_delta_step': 0,\n",
        "                'n_estimators': 94,\n",
        "                'max_deph': 11,\n",
        "                'gamma': 0,\n",
        "                'learning_rate': 1,\n",
        "                'base_score': 0.5,\n",
        "                'min_child_weight': 1,\n",
        "                'scale_pos_weight': 9,\n",
        "                'subsample': 1,\n",
        "                'colsample_bylevel': 1,\n",
        "                'colsample_bytree': 1,\n",
        "                'colsample_bynode': 1,\n",
        "                'reg_lambda': 1,\n",
        "              }\n",
        "\n",
        "xg_rf_classifier = XGBRFClassifier(**hyperparams)\n",
        "#print(f'parameters (xg_rf_classifier):\\n{xg_rf_classifier}')\n",
        "xg_rf_classifier_params = optimization(xg_rf_classifier)\n",
        "print(xg_rf_classifier_params)"
      ],
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: XGBRFClassifier(base_score=0.5, colsample_bylevel=1, colsample_bynode=1,\n",
            "                colsample_bytree=1, gamma=0, learning_rate=1, max_delta_step=0,\n",
            "                max_deph=11, max_depth=3, min_child_weight=1, missing=None,\n",
            "                n_estimators=94, n_jobs=1, nthread=-1,\n",
            "                objective='binary:logistic', random_state=0, reg_alpha=0,\n",
            "                reg_lambda=1, scale_pos_weight=9, seed=1909, silent=True,\n",
            "                subsample=1, verbosity=1)\n",
            "{'model__colsample_bylevel': 0.6699737886943773, 'model__colsample_bynode': 0.08615916646337052, 'model__colsample_bytree': 0.5493585594031315, 'model__subsample': 0.5115457995342926}\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "AzzGIcPscnZL",
        "colab_type": "text"
      },
      "source": [
        "# Evaluating Model with Optimized Parameter"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "s5C8ncl1bttg",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 289
        },
        "outputId": "c045cc9b-28d9-409f-9575-56442bd608ab"
      },
      "source": [
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.3, random_state = 1909)\n",
        "\n",
        "hyperparams = {'seed': 1909,\n",
        "                'nthread': -1,\n",
        "                'booster': 'gbtree',\n",
        "                'objective': 'binary:logistic',\n",
        "                'silent': True,\n",
        "                'reg_lambda': 1,\n",
        "                'missing': None,\n",
        "                'max_delta_step': 0,\n",
        "                'n_estimators': 120,\n",
        "                'max_deph': 3,\n",
        "                'gamma': 0,\n",
        "                'learning_rate': 0.05,\n",
        "                'base_score': 0.5,\n",
        "                'min_child_weight': 1,\n",
        "                'scale_pos_weight': 9,\n",
        "                'subsample': 1,\n",
        "                'colsample_bylevel': 1,\n",
        "                'colsample_bytree': 1,\n",
        "                'colsample_bynode': 1,\n",
        "                'reg_lambda': 1,\n",
        "              }\n",
        "\n",
        "xg_classifier = XGBClassifier(**hyperparams)\n",
        "evaluate_model(xg_classifier)\n",
        "evaluate_model_splitted(xg_classifier)"
      ],
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: XGBClassifier\n",
            "Average F1 on Training and Test Set: 56.86%/56.44%\n",
            "\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.83      0.99      0.90      8290\n",
            "           1       0.93      0.41      0.57      2831\n",
            "\n",
            "    accuracy                           0.84     11121\n",
            "   macro avg       0.88      0.70      0.74     11121\n",
            "weighted avg       0.86      0.84      0.82     11121\n",
            "\n",
            "[[8196 1661]\n",
            " [  94 1170]]\n",
            "---\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kTCQ1c78sK_5",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 408
        },
        "outputId": "98592bb5-adcc-487f-be6a-801b122c018c"
      },
      "source": [
        "hyperparams = {'random_state': 1909,\n",
        "                'nthread': -1,\n",
        "                'objective': 'binary:logistic',\n",
        "                'silent': True,\n",
        "                'reg_lambda': 1,\n",
        "                'missing': None,\n",
        "                'max_delta_step': 0,\n",
        "                'n_estimators': 96,\n",
        "                'max_deph': 11,\n",
        "                'gamma': 0,\n",
        "                'learning_rate': 0.05,\n",
        "                'base_score': 0.5,\n",
        "                'min_child_weight': 1,\n",
        "                'scale_pos_weight': 1,\n",
        "                'subsample': 1,\n",
        "                'colsample_bylevel': 1,\n",
        "                'colsample_bytree': 1,\n",
        "                'colsample_bynode': 1,\n",
        "                'reg_lambda': 1,\n",
        "              }\n",
        "\n",
        "xg_rf_classifier = XGBRFClassifier(**hyperparams)\n",
        "print(xg_rf_classifier)\n",
        "evaluate_model(xg_rf_classifier)\n",
        "evaluate_model_splitted(xg_rf_classifier)"
      ],
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "XGBRFClassifier(base_score=0.5, colsample_bylevel=1, colsample_bynode=1,\n",
            "                colsample_bytree=1, gamma=0, learning_rate=0.05,\n",
            "                max_delta_step=0, max_deph=11, max_depth=3, min_child_weight=1,\n",
            "                missing=None, n_estimators=96, n_jobs=1, nthread=-1,\n",
            "                objective='binary:logistic', random_state=1909, reg_alpha=0,\n",
            "                reg_lambda=1, scale_pos_weight=1, seed=None, silent=True,\n",
            "                subsample=1, verbosity=1)\n",
            "Model: XGBRFClassifier\n",
            "Average F1 on Training and Test Set: 59.15%/58.83%\n",
            "\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.95      0.95      0.95      9907\n",
            "           1       0.57      0.60      0.58      1214\n",
            "\n",
            "    accuracy                           0.91     11121\n",
            "   macro avg       0.76      0.77      0.77     11121\n",
            "weighted avg       0.91      0.91      0.91     11121\n",
            "\n",
            "[[9367  490]\n",
            " [ 540  724]]\n",
            "---\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3Zk-32TN030U",
        "colab_type": "text"
      },
      "source": [
        "# Prediction"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "n_zz_XTE1s8m",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 136
        },
        "outputId": "6294f33f-a060-4514-b1a9-e58100fddda9"
      },
      "source": [
        "xg_rf_classifier = XGBRFClassifier(**hyperparams)\n",
        "xg_rf_classifier.fit(X, y)"
      ],
      "execution_count": 53,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "XGBRFClassifier(base_score=0.5, colsample_bylevel=1, colsample_bynode=1,\n",
              "                colsample_bytree=1, gamma=0, learning_rate=0.05,\n",
              "                max_delta_step=0, max_deph=11, max_depth=3, min_child_weight=1,\n",
              "                missing=None, n_estimators=96, n_jobs=1, nthread=-1,\n",
              "                objective='binary:logistic', random_state=1909, reg_alpha=0,\n",
              "                reg_lambda=1, scale_pos_weight=1, seed=None, silent=True,\n",
              "                subsample=1, verbosity=1)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 53
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yUdizPNluYtJ",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "bd734f8a-5af2-41f0-ac31-608a8758d0bf"
      },
      "source": [
        "prediction_dataset = pd.read_csv(\n",
        "    'https://raw.githubusercontent.com/saschaschworm/big-data-and-data-science/master/datasets/prediction-challenge/prediction-dataset.csv', \n",
        "    index_col='identifier', parse_dates=['date'])\n",
        "\n",
        "prediction_dataset.insert(len(prediction_dataset.columns) -1, \"weekday\", prediction_dataset.date.dt.weekday)\n",
        "prediction_dataset.insert(len(prediction_dataset.columns) -1, \"day\", prediction_dataset.date.dt.day)\n",
        "prediction_dataset.insert(len(prediction_dataset.columns) -1, \"month\", prediction_dataset.date.dt.month)\n",
        "prediction_dataset.insert(len(prediction_dataset.columns) -1, \"year\", prediction_dataset.date.dt.year)\n",
        "prediction_dataset.insert(len(prediction_dataset.columns) -1, \"quarter\", prediction_dataset.date.dt.quarter)\n",
        "\n",
        "#prediction_dataset.insert(len(prediction_dataset.columns)-1, \"leitzins\", prediction_dataset['date'].apply(get_leitzins))\n",
        "prediction_dataset.insert(len(prediction_dataset.columns)-1, \"euribor\", prediction_dataset['date'].apply(get_euribor))\n",
        "#prediction_dataset.insert(len(prediction_dataset.columns)-1, \"cci\", prediction_dataset['date'].apply(get_cci))\n",
        "prediction_dataset.insert(len(prediction_dataset.columns)-1, \"cpi\", prediction_dataset['date'].apply(get_cpi))\n",
        "#prediction_dataset.insert(len(prediction_dataset.columns)-1, \"fsi\", prediction_dataset['date'].apply(get_fsi))\n",
        "#prediction_dataset.insert(len(prediction_dataset.columns)-1, \"eurostoxx\", prediction_dataset['date'].apply(get_eurostoxx))\n",
        "\n",
        "prediction_dataset = prediction_dataset.drop('date', axis=1)\n",
        "prediction_dataset.columns\n",
        "prediction_dataset['credit_default'].unique()"
      ],
      "execution_count": 54,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array(['No', 'Unknown'], dtype=object)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 54
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iZgREtHautSa",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "X_pred = prediction_dataset[['month', 'education', 'job', 'age', 'previous_conversion', 'n_contacts_before',\n",
        "       'days_since_last_contact', 'n_contacts_campaign', 'marital_status', 'credit_default',\n",
        "       'duration', 'housing_loan', 'personal_loan',\n",
        "       'euribor', 'cpi']]\n",
        "\n",
        "X_pred['credit_default'] = X_pred['credit_default'].apply(replace_loan)\n",
        "X_pred['personal_loan'] = X_pred['personal_loan'].apply(replace_loan)\n",
        "X_pred['housing_loan'] = X_pred['housing_loan'].apply(replace_loan)\n",
        "\n",
        "\n",
        "categorical_features = ['education', 'job', 'previous_conversion',\n",
        "                        'marital_status']\n",
        "\n",
        "for item in categorical_features:\n",
        "  try:\n",
        "    encoded = pd.get_dummies(X_pred[item], prefix=item)\n",
        "    X_pred.drop(item, axis=1, inplace=True)\n",
        "    X_pred = X_pred.join(encoded)\n",
        "  except Exception as e:\n",
        "    print(\"Something went wrong?!\")\n",
        "    print(e)\n",
        "    continue\n",
        "\n",
        "scaler = MinMaxScaler()\n",
        "numerical_features = ['n_contacts_campaign', 'duration', \n",
        "                  'days_since_last_contact', 'age',\n",
        "                  'euribor', 'cpi']\n",
        "\n",
        "X_pred[numerical_features] = scaler.fit_transform(X_pred[numerical_features])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "K1xqeSjDu1h1",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "predictions = xg_rf_classifier.predict(X_pred)\n",
        "\n",
        "submission = pd.DataFrame(\n",
        "    predictions, index=X_pred.index, columns=['prediction'])\n",
        "\n",
        "matriculation_number = '465527'\n",
        "\n",
        "submission.to_csv(\n",
        "    f'{mountpath}/My Drive/seminararbeit/result/submission-{matriculation_number}.csv', index_label='identifier')"
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}
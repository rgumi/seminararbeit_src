{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "feb-v7-dev.ipynb",
      "provenance": [],
      "toc_visible": true,
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/rgumi/seminararbeit_src/blob/master/feb_v7_dev.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oIo03i7VErog",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from scipy.stats import randint, uniform\n",
        "import datetime as dt\n",
        "import numpy as np\n",
        "import pandas as pd \n",
        "import json\n",
        "import urllib.request\n",
        "pd.options.mode.chained_assignment = None\n",
        "\n",
        "from sklearn.model_selection import train_test_split, cross_validate, RandomizedSearchCV, cross_val_score, RepeatedStratifiedKFold\n",
        "from sklearn.metrics import f1_score, make_scorer, confusion_matrix, accuracy_score, classification_report\n",
        "from sklearn.linear_model import LogisticRegression, SGDClassifier\n",
        "from sklearn.preprocessing import MinMaxScaler\n",
        "from xgboost import XGBClassifier, XGBRFClassifier\n",
        "\n",
        "\n",
        "from imblearn.metrics import classification_report_imbalanced"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "65g0sBlAx75d",
        "colab_type": "text"
      },
      "source": [
        "# Data Preprocessing\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "m8UHa8-ZyA22",
        "colab_type": "text"
      },
      "source": [
        "## Feature Additions"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hjf8i_m7vd3C",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "df_euribor = pd.read_csv(\n",
        "    'https://raw.githubusercontent.com/rgumi/seminararbeit_src/master/refined/euribor3m_ref.csv', \n",
        "    index_col=['index'], parse_dates=['date'])\n",
        "\n",
        "df_euribor = df_euribor[(df_euribor['date'].dt.year >= 2007)]\n",
        "\n",
        "def get_euribor(date):\n",
        "  for i in range(0, len(df_euribor)):\n",
        "\n",
        "    if date >= df_euribor['date'].iloc[i]:\n",
        "      last = df_euribor['value'].iloc[i]\n",
        "      continue\n",
        "    return round(last, 2)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8a8uQAdvOVte",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "df_eurostoxx= pd.read_csv(\n",
        "    'https://raw.githubusercontent.com/rgumi/seminararbeit_src/master/refined/eurostoxx_ref.csv', \n",
        "    index_col=['index'], parse_dates=['date'])\n",
        "\n",
        "df_eurostoxx = df_eurostoxx[(df_eurostoxx['date'].dt.year >= 2007)]\n",
        "\n",
        "def get_eurostoxx(date):\n",
        "  for i in range(0, len(df_eurostoxx)):\n",
        "\n",
        "    if date >= df_eurostoxx['date'].iloc[i]:\n",
        "      last = df_eurostoxx['value'].iloc[i]\n",
        "      continue\n",
        "    return last"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JS4n-_a4OgdJ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "df_fsi= pd.read_csv(\n",
        "    'https://raw.githubusercontent.com/rgumi/seminararbeit_src/master/refined/fsi_ref.csv', \n",
        "    index_col=['index'], parse_dates=['Date'])\n",
        "\n",
        "df_fsi = df_fsi[(df_fsi['Date'].dt.year >= 2007)]\n",
        "\n",
        "def get_fsi(date):\n",
        "  for i in range(0, len(df_fsi)):\n",
        "\n",
        "    if date >= df_fsi['Date'].iloc[i]:\n",
        "      # Possible values: [OFR FSI, Credit, Equity valuation, Safe assets, Funding, Volatility]\n",
        "      last = df_fsi['OFR FSI'].iloc[i]\n",
        "      continue\n",
        "    return last"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "33cyR0R7Llxb",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "df_cpi = pd.read_csv(\n",
        "    'https://raw.githubusercontent.com/rgumi/seminararbeit_src/master/refined/cpi_monthly_ref.csv', \n",
        "    index_col=['index'], parse_dates=['date'])\n",
        "\n",
        "df_cpi = df_cpi[(df_cpi['date'].dt.year >= 2007)]\n",
        "\n",
        "def get_cpi(date):\n",
        "  for i in range(0, len(df_cpi)):\n",
        "\n",
        "    if date >= df_cpi['date'].iloc[i]:\n",
        "      last = df_cpi['value'].iloc[i]\n",
        "      continue\n",
        "    return last"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EgxhChjBLUCc",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "df_cci = pd.read_csv(\n",
        "    'https://raw.githubusercontent.com/rgumi/seminararbeit_src/master/refined/cci_monthly_ref.csv', \n",
        "    index_col=['index'], parse_dates=['date'])\n",
        "\n",
        "df_cci = df_cci[(df_cci['date'].dt.year >= 2007)]\n",
        "\n",
        "def get_cci(date):\n",
        "  for i in range(0, len(df_cci)):\n",
        "\n",
        "    if date >= df_cci['date'].iloc[i]:\n",
        "      last = df_cci['value'].iloc[i]\n",
        "      continue\n",
        "      \n",
        "    return last"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AYAngATPuYD4",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "ltz = {}\n",
        "with urllib.request.urlopen(\"https://raw.githubusercontent.com/rgumi/seminararbeit_src/master/refined/leitzinsen_eu.json\") as url:\n",
        "    tmp_ltz = json.loads(url.read().decode())\n",
        "for key in tmp_ltz.keys():\n",
        "  ltz[dt.datetime.strptime(key, '%d-%m-%Y')] = tmp_ltz[key]\n",
        "sorted_ltz = {k: ltz[k] for k in sorted(ltz)}\n",
        "\n",
        "def get_leitzins(date):\n",
        "  for key, val in sorted_ltz.items():\n",
        "    if date >= key:\n",
        "      last = val\n",
        "      continue\n",
        "    return last"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yzmRpRnartCw",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def replace_loan(loan):\n",
        "  if loan == 'Unknown':\n",
        "    return 1\n",
        "  if loan == 'No':\n",
        "    return 2\n",
        "  if loan == 'Yes':\n",
        "    return 3"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "l0IQ5mkTyTBt",
        "colab_type": "text"
      },
      "source": [
        "# Pipeline"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "f8rRxxjwEm-M",
        "colab_type": "code",
        "outputId": "0bdc9e4e-0856-427d-e0fe-ab079f167658",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 145
        }
      },
      "source": [
        "dataset = pd.read_csv(\n",
        "    'https://raw.githubusercontent.com/saschaschworm/big-data-and-data-science/master/datasets/prediction-challenge/dataset.csv', \n",
        "    index_col='identifier', parse_dates=['date'])\n",
        "\n",
        "dataset.insert(len(dataset.columns) -1, \"weekday\", dataset.date.dt.weekday)\n",
        "dataset.insert(len(dataset.columns) -1, \"day\", dataset.date.dt.day)\n",
        "dataset.insert(len(dataset.columns) -1, \"month\", dataset.date.dt.month)\n",
        "dataset.insert(len(dataset.columns) -1, \"year\", dataset.date.dt.year)\n",
        "dataset.insert(len(dataset.columns) -1, \"quarter\", dataset.date.dt.quarter)\n",
        "\n",
        "dataset.insert(len(dataset.columns)-1, \"leitzins\", dataset['date'].apply(get_leitzins))\n",
        "dataset.insert(len(dataset.columns)-1, \"euribor\", dataset['date'].apply(get_euribor))\n",
        "dataset.insert(len(dataset.columns)-1, \"cci\", dataset['date'].apply(get_cci))\n",
        "dataset.insert(len(dataset.columns)-1, \"cpi\", dataset['date'].apply(get_cpi))\n",
        "dataset.insert(len(dataset.columns)-1, \"fsi\", dataset['date'].apply(get_fsi))\n",
        "dataset.insert(len(dataset.columns)-1, \"eurostoxx\", dataset['date'].apply(get_eurostoxx))\n",
        "\n",
        "dataset = dataset.drop('date', axis=1)\n",
        "\n",
        "dataset.loc[dataset['days_since_last_contact'] == -1, 'days_since_last_contact'] = 10000\n",
        "\n",
        "dataset.columns"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Index(['age', 'marital_status', 'education', 'job', 'credit_default',\n",
              "       'housing_loan', 'personal_loan', 'communication_type',\n",
              "       'n_contacts_campaign', 'days_since_last_contact', 'n_contacts_before',\n",
              "       'previous_conversion', 'duration', 'weekday', 'day', 'month', 'year',\n",
              "       'quarter', 'leitzins', 'euribor', 'cci', 'cpi', 'fsi', 'eurostoxx',\n",
              "       'success'],\n",
              "      dtype='object')"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 10
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "chldv7-yEP04",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "X = dataset[['quarter', 'education', 'job', 'age', 'previous_conversion', 'n_contacts_before',\n",
        "       'days_since_last_contact', 'n_contacts_campaign', 'marital_status', 'credit_default',\n",
        "       'duration', 'housing_loan', 'personal_loan',\n",
        "       'euribor', 'leitzins', 'eurostoxx',\n",
        "       ]]\n",
        "       \n",
        "y = dataset['success']\n",
        "y = y.apply(lambda x: 1 if x == \"Yes\" else 0)\n",
        "\n",
        "X['credit_default'] = X['credit_default'].apply(replace_loan)\n",
        "X['personal_loan'] = X['personal_loan'].apply(replace_loan)\n",
        "X['housing_loan'] = X['housing_loan'].apply(replace_loan)\n",
        "\n",
        "\n",
        "categorical_features = ['education', 'job', 'previous_conversion',\n",
        "                        'marital_status']\n",
        "\n",
        "for item in categorical_features:\n",
        "  try:\n",
        "    encoded = pd.get_dummies(X[item], prefix=item)\n",
        "    X.drop(item, axis=1, inplace=True)\n",
        "    X = X.join(encoded)\n",
        "  except Exception as e:\n",
        "    print(\"Something went wrong?!\")\n",
        "    print(e)\n",
        "    continue\n",
        "\n",
        "scaler = MinMaxScaler()\n",
        "numerical_features = ['n_contacts_campaign', 'duration', \n",
        "                  'days_since_last_contact', 'age',\n",
        "                  'euribor', 'leitzins', 'eurostoxx', \n",
        "                  ]\n",
        "\n",
        "X[numerical_features] = scaler.fit_transform(X[numerical_features])\n",
        "X"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6P7d4DFsXiyB",
        "colab_type": "text"
      },
      "source": [
        "# Hyperparameter optimization"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "L1cXNmVcZ5KR",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "custom_scorer = make_scorer(f1_score, pos_label=1)\n",
        "# randomized hyperparameter optimization\n",
        "# https://www.analyticsvidhya.com/blog/2016/03/complete-guide-parameter-tuning-xgboost-with-codes-python/\n",
        "def optimization(model):\n",
        "  print(f'Model: {str(model)}')\n",
        "  ## default is 3\n",
        "  n_estimators = randint(90, 150)\n",
        "  ## default is 100\n",
        "  max_depth = randint(5, 25)\n",
        "  ## default is 0.1 and 1 respectively\n",
        "  learning_rate = uniform()\n",
        "\n",
        "  # Sampling\n",
        "  ## default is 1\n",
        "  colsample_bytree = uniform()\n",
        "  ## default is 1\n",
        "  colsample_bylevel = uniform()\n",
        "  ## default is 1\n",
        "  colsample_bynode = uniform()\n",
        "\n",
        "  # default is 1\n",
        "  min_child_weight = uniform()\n",
        "\n",
        "\n",
        "  gamma = uniform()\n",
        "  base_score = uniform()\n",
        "  subsample = uniform()\n",
        "\n",
        "  # optimization parameters\n",
        "  param_distributions = {'model__n_estimators': n_estimators,\n",
        "                         'model__max_depth': max_depth,\n",
        "                         'model__gamma': gamma,\n",
        "                         'model__min_child_weight': min_child_weight,\n",
        "                         'model__base_score': base_score,\n",
        "                         'model__subsample': subsample,\n",
        "                         'model__colsample_bylevel': colsample_bylevel,\n",
        "                         'model__colsample_bytree': colsample_bytree,\n",
        "                         'model__colsample_bynode': colsample_bynode,\n",
        "                        }\n",
        "                        \n",
        "  search = RandomizedSearchCV(model, param_distributions=param_distributions, n_iter=20,\n",
        "                        scoring=custom_scorer, n_jobs=-1, cv=10, random_state=1909)\n",
        "  \n",
        "  search = search.fit(X, y)\n",
        "  return search.best_params_"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "023_1lMnPCtg",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from xgboost import XGBClassifier\n",
        "\n",
        "hyperparams = {'seed': 1909,\n",
        "                'nthread': -1,\n",
        "                'booster': 'gbtree',\n",
        "                'objective': 'binary:logistic',\n",
        "                'silent': True,\n",
        "                'reg_lambda': 1,\n",
        "                'missing': None,\n",
        "                'max_delta_step': 0,\n",
        "                'n_estimators': 94,\n",
        "                'max_deph': 11,\n",
        "                'gamma': 0,\n",
        "                'learning_rate': 0.3,\n",
        "                'base_score': 0.5,\n",
        "                'min_child_weight': 1,\n",
        "                'scale_pos_weight': 9,\n",
        "                'subsample': 1,\n",
        "                'colsample_bylevel': 1,\n",
        "                'colsample_bytree': 1,\n",
        "                'colsample_bynode': 1,\n",
        "                'reg_lambda': 1,\n",
        "              }\n",
        "\n",
        "xg_classifier = XGBClassifier(**hyperparams)\n",
        "xg_classifier_params = optimization(xg_classifier)\n",
        "\n",
        "print(xg_classifier_params)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "AzzGIcPscnZL",
        "colab_type": "text"
      },
      "source": [
        "# Evaluating Model with Optimized Parameter"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-Bq8TKCUt_Zs",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "hyperparams = {'seed': 1909, \n",
        "               'learning_rate': 0.3, \n",
        "               'min_child_weight': xg_classifier_params['model__min_child_weight'], \n",
        "               'scale_pos_weight': 8, \n",
        "               'colsample_bylevel': 0.8, # xg_classifier_params['model__colsample_bylevel'], \n",
        "               'colsample_bytree': xg_classifier_params['model__colsample_bytree'], \n",
        "               'colsample_bynode': xg_classifier_params['model__colsample_bynode'], \n",
        "               'max_depth': xg_classifier_params['model__max_depth'], \n",
        "               'n_estimators': xg_classifier_params['model__n_estimators'], \n",
        "               'gamma': xg_classifier_params['model__gamma'], \n",
        "               'subsample': xg_classifier_params['model__subsample'], \n",
        "               'base_score': xg_classifier_params['model__base_score'], \n",
        "               'reg_lambda': 1, \n",
        "               'nthread': -1, 'booster': 'gbtree', \n",
        "               'objective': 'binary:logistic', 'silent': True, \n",
        "               'missing': None, 'max_delta_step': 0\n",
        "}\n",
        "\n",
        "model = XGBClassifier(**hyperparams)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hLpCaYWnx1OG",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "cv = RepeatedStratifiedKFold(n_splits=10, n_repeats=3, random_state=1909)\n",
        "scores = cross_validate(model, X, y, scoring='roc_auc', cv=cv, n_jobs=-1, return_train_score=True)\n",
        "print(f'Mean Roc_Auc Score: {np.mean(scores[\"train_score\"])*100:.2f}/{np.mean(scores[\"test_score\"])*100:.2f}')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "a0C3-sT2vavz",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "cv = RepeatedStratifiedKFold(n_splits=10, n_repeats=3, random_state=1909)\n",
        "scores = cross_validate(model, X, y, scoring='f1', cv=cv, n_jobs=-1, return_train_score=True)\n",
        "print(f'Mean F1 Score: {np.mean(scores[\"train_score\"])*100:.2f}/{np.mean(scores[\"test_score\"])*100:.2f}')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6Yq3wayYwhLT",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.3, random_state = 1909)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gC4O0MskwwZt",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "model.fit(X_train, y_train)\n",
        "\n",
        "y_pred = model.predict(X_test)\n",
        "\n",
        "print(classification_report(y_pred, y_test))\n",
        "print(confusion_matrix(y_pred, y_test))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0sqIdknyWMUC",
        "colab_type": "text"
      },
      "source": [
        "# Test Oversampling"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8229yv2NWE8L",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def roc_cv_score(model, X, y):\n",
        "  cv = RepeatedStratifiedKFold(n_splits=10, n_repeats=3, random_state=1909)\n",
        "  scores = cross_validate(model, X, y, scoring='roc_auc', cv=cv, n_jobs=-1, return_train_score=True)\n",
        "  print(f'Mean Roc_Auc Score: {np.mean(scores[\"train_score\"])*100:.2f}/{np.mean(scores[\"test_score\"])*100:.2f}')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xGNOkcLYWCGC",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def f1_cv_score(model, X, y):\n",
        "  cv = RepeatedStratifiedKFold(n_splits=10, n_repeats=3, random_state=1909)\n",
        "  scores = cross_validate(model, X, y, scoring='f1', cv=cv, n_jobs=-1, return_train_score=True)\n",
        "  print(f'Mean F1 Score: {np.mean(scores[\"train_score\"])*100:.2f}/{np.mean(scores[\"test_score\"])*100:.2f}')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1oB2G04KWLBu",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "hyperparams = {\n",
        "    'seed': 1909,\n",
        "    'nthread': -1,\n",
        "    'booster': 'gbtree',\n",
        "    'objective': 'binary:logistic',\n",
        "    'silent': True,\n",
        "    'reg_lambda': 1,\n",
        "    'missing': None,\n",
        "    'max_delta_step': 0,\n",
        "    'n_estimators': 250,\n",
        "    'max_deph': 3,\n",
        "    'gamma': 0,\n",
        "    'learning_rate': 0.12,\n",
        "    'base_score': 0.5,\n",
        "    'min_child_weight': 1,\n",
        "    'scale_pos_weight': 1,\n",
        "    'subsample': 1,\n",
        "    'colsample_bylevel': 1,\n",
        "    'colsample_bytree': 1,\n",
        "    'colsample_bynode': 1,\n",
        "    'reg_lambda': 1,\n",
        "}\n",
        "\n",
        "\n",
        "\n",
        "hyperparams = {\n",
        "    'n_estimators': 150,\n",
        "    'max_deph': 8,\n",
        "    'learning_rate': 0.10,\n",
        "    'base_score': 0.5,\n",
        "    'min_child_weight': 1,\n",
        "    'gamma': 0,\n",
        "    'subsample': 0.6,\n",
        "    'colsample_bylevel': 1,\n",
        "    'colsample_bytree': 1,\n",
        "    'colsample_bynode': 1,\n",
        "    'reg_lambda': 1,\n",
        "    'max_delta_step ': 0,\n",
        "    'scale_pos_weight': 1,\n",
        "}\n",
        "\n",
        "\n",
        "hyperparams = {\n",
        "    'n_estimators': 100,\n",
        "    'max_deph': 50,\n",
        "    'learning_rate': 0.2,\n",
        "    'base_score': 0.5,\n",
        "    'min_child_weight': 0.8,\n",
        "    'gamma': 2,\n",
        "    'subsample': 0.25,\n",
        "    'colsample_bylevel': 0.75,\n",
        "    'colsample_bytree': 0.65,\n",
        "    'colsample_bynode': 0.75,\n",
        "    'reg_lambda': 1,\n",
        "    'max_delta_step ': 0,\n",
        "    'scale_pos_weight': 1,\n",
        "}"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "inFnwIhbUn4r",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        " from imblearn.over_sampling import SMOTE, ADASYN\n",
        " from collections import Counter\n",
        "\n",
        " X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.3, random_state = 1909)\n",
        "\n",
        "print(sorted(Counter(y_train).items()))\n",
        "print(sorted(Counter(y_test).items()))\n",
        "\n",
        "X_resampled, y_resampled = ADASYN(random_state = 1909).fit_resample(X_train, y_train)\n",
        "X_r_train = pd.DataFrame(X_resampled, columns=X.columns)\n",
        "print(sorted(Counter(y_resampled).items()))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "k-pbtshFd3yp",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "model = XGBClassifier(**hyperparams)\n",
        "model.fit(X_r_train, y_resampled)\n",
        "\n",
        "y_pred = model.predict(X_test)\n",
        "\n",
        "print(classification_report(y_pred, y_test))\n",
        "print(confusion_matrix(y_pred, y_test))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "t-hSJY0Amims",
        "colab_type": "code",
        "outputId": "677226b5-b5ae-4e20-b99f-6192e2ab52ec",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 235
        }
      },
      "source": [
        "from sklearn.ensemble import RandomForestClassifier, RandomForestRegressor\n",
        "#model = RandomForestRegressor(criterion= 'mse')\n",
        "model = RandomForestClassifier(n_estimators=150, max_depth=10)\n",
        "f1_cv_score(model, X, y)\n",
        "model.fit(X_r_train, y_resampled)\n",
        "\n",
        "y_pred = model.predict(X_test)\n",
        "\n",
        "print(classification_report(y_pred, y_test))\n",
        "print(confusion_matrix(y_pred, y_test))"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Mean F1 Score: 54.69/42.73\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.87      0.98      0.92      8789\n",
            "           1       0.87      0.47      0.61      2332\n",
            "\n",
            "    accuracy                           0.87     11121\n",
            "   macro avg       0.87      0.73      0.77     11121\n",
            "weighted avg       0.87      0.87      0.86     11121\n",
            "\n",
            "[[8621  168]\n",
            " [1236 1096]]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YrHG5ur1o-qj",
        "colab_type": "code",
        "outputId": "1d855b27-4a21-4ae5-b9fe-eefe27eb2199",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 217
        }
      },
      "source": [
        "_y_pred = []\n",
        "for x in y_pred:\n",
        "  a = 0\n",
        "  if x > 0.6:\n",
        "    a = 1\n",
        "  _y_pred.append(a)\n",
        "print(classification_report(_y_pred, y_test))\n",
        "print(confusion_matrix(_y_pred, y_test))"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.95      0.94      0.94      9925\n",
            "           1       0.53      0.56      0.55      1196\n",
            "\n",
            "    accuracy                           0.90     11121\n",
            "   macro avg       0.74      0.75      0.75     11121\n",
            "weighted avg       0.90      0.90      0.90     11121\n",
            "\n",
            "[[9336  589]\n",
            " [ 521  675]]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hNhF8zQmkE4j",
        "colab_type": "code",
        "outputId": "1bb42ccb-f2d0-4df3-f6d9-fba9ea9b7777",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 343
        }
      },
      "source": [
        "from imblearn.over_sampling import SMOTE, ADASYN\n",
        "from imblearn.combine import SMOTETomek\n",
        "\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.3, random_state = 1909)\n",
        "print(sorted(Counter(y_train).items()))\n",
        "print(sorted(Counter(y_test).items()))\n",
        "\n",
        "X_resampled, y_resampled = SMOTETomek(random_state = 1909).fit_resample(X_train, y_train)\n",
        "X_r_train = pd.DataFrame(X_resampled, columns=X.columns)\n",
        "print(sorted(Counter(y_resampled).items()))\n",
        "\n",
        "\n",
        "model = XGBClassifier(**hyperparams)\n",
        "model.fit(X_r_train, y_resampled)\n",
        "\n",
        "y_pred = model.predict(X_test)\n",
        "\n",
        "print(classification_report(y_pred, y_test))\n",
        "print(confusion_matrix(y_pred, y_test))"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[(0, 23036), (1, 2912)]\n",
            "[(0, 9857), (1, 1264)]\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/sklearn/utils/deprecation.py:87: FutureWarning: Function safe_indexing is deprecated; safe_indexing is deprecated in version 0.22 and will be removed in version 0.24.\n",
            "  warnings.warn(msg, category=FutureWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/utils/deprecation.py:87: FutureWarning: Function safe_indexing is deprecated; safe_indexing is deprecated in version 0.22 and will be removed in version 0.24.\n",
            "  warnings.warn(msg, category=FutureWarning)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "[(0, 22767), (1, 22767)]\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.92      0.97      0.94      9415\n",
            "           1       0.75      0.55      0.64      1706\n",
            "\n",
            "    accuracy                           0.90     11121\n",
            "   macro avg       0.83      0.76      0.79     11121\n",
            "weighted avg       0.90      0.90      0.90     11121\n",
            "\n",
            "[[9094  321]\n",
            " [ 763  943]]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9-2MRh2UoRcF",
        "colab_type": "text"
      },
      "source": [
        "# Test Undersampling"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HpceKeDRmpx5",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from imblearn.under_sampling import RandomUnderSampler\n",
        "\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.3, random_state = 1909)\n",
        "print(sorted(Counter(y_train).items()))\n",
        "print(sorted(Counter(y_test).items()))\n",
        "\n",
        "X_resampled, y_resampled = RandomUnderSampler(random_state = 1909).fit_resample(X_train, y_train)\n",
        "X_r_train = pd.DataFrame(X_resampled, columns=X.columns)\n",
        "print(sorted(Counter(y_resampled).items()))\n",
        "\n",
        "model = XGBClassifier(**hyperparams)\n",
        "model.fit(X_r_train, y_resampled)\n",
        "\n",
        "y_pred = model.predict(X_test)\n",
        "\n",
        "print(classification_report(y_pred, y_test))\n",
        "print(confusion_matrix(y_pred, y_test))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FTnMHUcdnIHn",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from imblearn.under_sampling import ClusterCentroids\n",
        "\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.3, random_state = 1909)\n",
        "print(sorted(Counter(y_train).items()))\n",
        "print(sorted(Counter(y_test).items()))\n",
        "\n",
        "X_resampled, y_resampled = ClusterCentroids(random_state = 1909).fit_resample(X_train, y_train)\n",
        "X_r_train = pd.DataFrame(X_resampled, columns=X.columns)\n",
        "print(sorted(Counter(y_resampled).items()))\n",
        "\n",
        "model = XGBClassifier(**hyperparams)\n",
        "model.fit(X_r_train, y_resampled)\n",
        "\n",
        "y_pred = model.predict(X_test)\n",
        "\n",
        "print(classification_report(y_pred, y_test))\n",
        "print(confusion_matrix(y_pred, y_test))"
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}
{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "feb-v5-dev.ipynb",
      "provenance": [],
      "toc_visible": true,
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/rgumi/seminararbeit_src/blob/master/feb_v5_dev.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oIo03i7VErog",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from scipy.stats import randint, uniform\n",
        "import datetime as dt\n",
        "import numpy as np\n",
        "import pandas as pd \n",
        "import json\n",
        "import urllib.request\n",
        "pd.options.mode.chained_assignment = None\n",
        "\n",
        "from sklearn.model_selection import train_test_split, cross_validate, RandomizedSearchCV, cross_val_score, RepeatedStratifiedKFold\n",
        "from sklearn.metrics import f1_score, make_scorer, confusion_matrix, accuracy_score, classification_report\n",
        "from sklearn.linear_model import LogisticRegression, SGDClassifier\n",
        "from sklearn.preprocessing import MinMaxScaler\n",
        "from xgboost.sklearn import XGBClassifier\n",
        "from xgboost import XGBRFClassifier"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "65g0sBlAx75d",
        "colab_type": "text"
      },
      "source": [
        "# Data Preprocessing\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "m8UHa8-ZyA22",
        "colab_type": "text"
      },
      "source": [
        "## Feature Additions"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hjf8i_m7vd3C",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "df_euribor = pd.read_csv(\n",
        "    'https://raw.githubusercontent.com/rgumi/seminararbeit_src/master/refined/euribor3m_ref.csv', \n",
        "    index_col=['index'], parse_dates=['date'])\n",
        "\n",
        "df_euribor = df_euribor[(df_euribor['date'].dt.year >= 2007)]\n",
        "\n",
        "def get_euribor(date):\n",
        "  for i in range(0, len(df_euribor)):\n",
        "\n",
        "    if date >= df_euribor['date'].iloc[i]:\n",
        "      last = df_euribor['value'].iloc[i]\n",
        "      continue\n",
        "    return round(last, 2)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8a8uQAdvOVte",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "df_eurostoxx= pd.read_csv(\n",
        "    'https://raw.githubusercontent.com/rgumi/seminararbeit_src/master/refined/eurostoxx_ref.csv', \n",
        "    index_col=['index'], parse_dates=['date'])\n",
        "\n",
        "df_eurostoxx = df_eurostoxx[(df_eurostoxx['date'].dt.year >= 2007)]\n",
        "\n",
        "def get_eurostoxx(date):\n",
        "  for i in range(0, len(df_eurostoxx)):\n",
        "\n",
        "    if date >= df_eurostoxx['date'].iloc[i]:\n",
        "      last = df_eurostoxx['value'].iloc[i]\n",
        "      continue\n",
        "    return last"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JS4n-_a4OgdJ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "df_fsi= pd.read_csv(\n",
        "    'https://raw.githubusercontent.com/rgumi/seminararbeit_src/master/refined/fsi_ref.csv', \n",
        "    index_col=['index'], parse_dates=['Date'])\n",
        "\n",
        "df_fsi = df_fsi[(df_fsi['Date'].dt.year >= 2007)]\n",
        "\n",
        "def get_fsi(date):\n",
        "  for i in range(0, len(df_fsi)):\n",
        "\n",
        "    if date >= df_fsi['Date'].iloc[i]:\n",
        "      # Possible values: [OFR FSI, Credit, Equity valuation, Safe assets, Funding, Volatility]\n",
        "      last = df_fsi['OFR FSI'].iloc[i]\n",
        "      continue\n",
        "    return last"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "33cyR0R7Llxb",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "df_cpi = pd.read_csv(\n",
        "    'https://raw.githubusercontent.com/rgumi/seminararbeit_src/master/refined/cpi_monthly_ref.csv', \n",
        "    index_col=['index'], parse_dates=['date'])\n",
        "\n",
        "df_cpi = df_cpi[(df_cpi['date'].dt.year >= 2007)]\n",
        "\n",
        "def get_cpi(date):\n",
        "  for i in range(0, len(df_cpi)):\n",
        "\n",
        "    if date >= df_cpi['date'].iloc[i]:\n",
        "      last = df_cpi['value'].iloc[i]\n",
        "      continue\n",
        "    return last"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EgxhChjBLUCc",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "df_cci = pd.read_csv(\n",
        "    'https://raw.githubusercontent.com/rgumi/seminararbeit_src/master/refined/cci_monthly_ref.csv', \n",
        "    index_col=['index'], parse_dates=['date'])\n",
        "\n",
        "df_cci = df_cci[(df_cci['date'].dt.year >= 2007)]\n",
        "\n",
        "def get_cci(date):\n",
        "  for i in range(0, len(df_cci)):\n",
        "\n",
        "    if date >= df_cci['date'].iloc[i]:\n",
        "      last = df_cci['value'].iloc[i]\n",
        "      continue\n",
        "      \n",
        "    return last"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AYAngATPuYD4",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "ltz = {}\n",
        "with urllib.request.urlopen(\"https://raw.githubusercontent.com/rgumi/seminararbeit_src/master/refined/leitzinsen_eu.json\") as url:\n",
        "    tmp_ltz = json.loads(url.read().decode())\n",
        "for key in tmp_ltz.keys():\n",
        "  ltz[dt.datetime.strptime(key, '%d-%m-%Y')] = tmp_ltz[key]\n",
        "sorted_ltz = {k: ltz[k] for k in sorted(ltz)}\n",
        "\n",
        "def get_leitzins(date):\n",
        "  for key, val in sorted_ltz.items():\n",
        "    if date >= key:\n",
        "      last = val\n",
        "      continue\n",
        "    return last"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yzmRpRnartCw",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def replace_loan(loan):\n",
        "  if loan == 'Unknown':\n",
        "    return 1\n",
        "  if loan == 'No':\n",
        "    return 2\n",
        "  if loan == 'Yes':\n",
        "    return 3"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "l0IQ5mkTyTBt",
        "colab_type": "text"
      },
      "source": [
        "# Pipeline"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "f8rRxxjwEm-M",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 136
        },
        "outputId": "960527c9-5f12-4715-da55-d9ca533e0ad3"
      },
      "source": [
        "dataset = pd.read_csv(\n",
        "    'https://raw.githubusercontent.com/saschaschworm/big-data-and-data-science/master/datasets/prediction-challenge/dataset.csv', \n",
        "    index_col='identifier', parse_dates=['date'])\n",
        "\n",
        "dataset.insert(len(dataset.columns) -1, \"weekday\", dataset.date.dt.weekday)\n",
        "dataset.insert(len(dataset.columns) -1, \"day\", dataset.date.dt.day)\n",
        "dataset.insert(len(dataset.columns) -1, \"month\", dataset.date.dt.month)\n",
        "dataset.insert(len(dataset.columns) -1, \"year\", dataset.date.dt.year)\n",
        "dataset.insert(len(dataset.columns) -1, \"quarter\", dataset.date.dt.quarter)\n",
        "\n",
        "dataset.insert(len(dataset.columns)-1, \"leitzins\", dataset['date'].apply(get_leitzins))\n",
        "dataset.insert(len(dataset.columns)-1, \"euribor\", dataset['date'].apply(get_euribor))\n",
        "dataset.insert(len(dataset.columns)-1, \"cci\", dataset['date'].apply(get_cci))\n",
        "dataset.insert(len(dataset.columns)-1, \"cpi\", dataset['date'].apply(get_cpi))\n",
        "dataset.insert(len(dataset.columns)-1, \"fsi\", dataset['date'].apply(get_fsi))\n",
        "dataset.insert(len(dataset.columns)-1, \"eurostoxx\", dataset['date'].apply(get_eurostoxx))\n",
        "\n",
        "dataset = dataset.drop('date', axis=1)\n",
        "\n",
        "dataset.loc[dataset['days_since_last_contact'] == -1, 'days_since_last_contact'] = 10000\n",
        "\n",
        "dataset.columns"
      ],
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Index(['age', 'marital_status', 'education', 'job', 'credit_default',\n",
              "       'housing_loan', 'personal_loan', 'communication_type',\n",
              "       'n_contacts_campaign', 'days_since_last_contact', 'n_contacts_before',\n",
              "       'previous_conversion', 'duration', 'weekday', 'day', 'month', 'year',\n",
              "       'quarter', 'leitzins', 'euribor', 'cci', 'cpi', 'fsi', 'eurostoxx',\n",
              "       'success'],\n",
              "      dtype='object')"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 9
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "chldv7-yEP04",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "X = dataset[['quarter', 'education', 'job', 'age', 'previous_conversion', 'n_contacts_before',\n",
        "       'days_since_last_contact', 'n_contacts_campaign', 'marital_status', 'credit_default',\n",
        "       'duration', 'housing_loan', 'personal_loan',\n",
        "       'euribor', 'leitzins', 'eurostoxx', 'fsi', 'cci', 'cpi', ]]\n",
        "       \n",
        "y = dataset['success']\n",
        "y = y.apply(lambda x: 1 if x == \"Yes\" else 0)\n",
        "\n",
        "X['credit_default'] = X['credit_default'].apply(replace_loan)\n",
        "X['personal_loan'] = X['personal_loan'].apply(replace_loan)\n",
        "X['housing_loan'] = X['housing_loan'].apply(replace_loan)\n",
        "\n",
        "\n",
        "categorical_features = ['education', 'job', 'previous_conversion',\n",
        "                        'marital_status', 'quarter']\n",
        "\n",
        "for item in categorical_features:\n",
        "  try:\n",
        "    encoded = pd.get_dummies(X[item], prefix=item)\n",
        "    X.drop(item, axis=1, inplace=True)\n",
        "    X = X.join(encoded)\n",
        "  except Exception as e:\n",
        "    print(\"Something went wrong?!\")\n",
        "    print(e)\n",
        "    continue\n",
        "\n",
        "scaler = MinMaxScaler()\n",
        "numerical_features = ['n_contacts_campaign', 'duration', \n",
        "                  'days_since_last_contact', 'age',\n",
        "                  'euribor', 'leitzins', 'eurostoxx', 'fsi', 'cci', 'cpi', ]\n",
        "\n",
        "\n",
        "X[numerical_features] = scaler.fit_transform(X[numerical_features])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6P7d4DFsXiyB",
        "colab_type": "text"
      },
      "source": [
        "# Hyperparameter optimization"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "L1cXNmVcZ5KR",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "custom_scorer = make_scorer(f1_score, pos_label=1)\n",
        "# randomized hyperparameter optimization\n",
        "# https://www.analyticsvidhya.com/blog/2016/03/complete-guide-parameter-tuning-xgboost-with-codes-python/\n",
        "def optimization(model):\n",
        "  print(f'Model: {str(model)}')\n",
        "  ## default is 3\n",
        "  n_estimators = randint(90, 150)\n",
        "  ## default is 100\n",
        "  max_depth = randint(5, 25)\n",
        "  ## default is 0.1 and 1 respectively\n",
        "  learning_rate = uniform()\n",
        "\n",
        "  # Sampling\n",
        "  ## default is 1\n",
        "  colsample_bytree = uniform()\n",
        "  ## default is 1\n",
        "  colsample_bylevel = uniform()\n",
        "  ## default is 1\n",
        "  colsample_bynode = uniform()\n",
        "\n",
        "  # default is 1\n",
        "  min_child_weight = uniform()\n",
        "\n",
        "\n",
        "  gamma = uniform()\n",
        "  base_score = uniform()\n",
        "  subsample = uniform()\n",
        "\n",
        "  # optimization parameters\n",
        "  param_distributions = {'model__n_estimators': n_estimators,\n",
        "                         'model__max_depth': max_depth,\n",
        "                         'model__gamma': gamma,\n",
        "                         'model__min_child_weight': min_child_weight,\n",
        "                         'model__base_score': base_score,\n",
        "                         'model__subsample': subsample,\n",
        "                         'model__colsample_bylevel': colsample_bylevel,\n",
        "                         'model__colsample_bytree': colsample_bytree,\n",
        "                         'model__colsample_bynode': colsample_bynode,\n",
        "                        }\n",
        "                        \n",
        "  search = RandomizedSearchCV(model, param_distributions=param_distributions, n_iter=20,\n",
        "                        scoring=custom_scorer, n_jobs=-1, cv=10, random_state=1909)\n",
        "  \n",
        "  search = search.fit(X, y)\n",
        "  return search.best_params_"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "023_1lMnPCtg",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 173
        },
        "outputId": "91dd381e-cad5-49a4-e3c4-aebef30f7d07"
      },
      "source": [
        "from xgboost import XGBClassifier\n",
        "\n",
        "hyperparams = {'seed': 1909,\n",
        "                'nthread': -1,\n",
        "                'booster': 'gbtree',\n",
        "                'objective': 'binary:logistic',\n",
        "                'silent': True,\n",
        "                'reg_lambda': 1,\n",
        "                'missing': None,\n",
        "                'max_delta_step': 0,\n",
        "                'n_estimators': 94,\n",
        "                'max_deph': 11,\n",
        "                'gamma': 0,\n",
        "                'learning_rate': 0.3,\n",
        "                'base_score': 0.5,\n",
        "                'min_child_weight': 1,\n",
        "                'scale_pos_weight': 9,\n",
        "                'subsample': 1,\n",
        "                'colsample_bylevel': 1,\n",
        "                'colsample_bytree': 1,\n",
        "                'colsample_bynode': 1,\n",
        "                'reg_lambda': 1,\n",
        "              }\n",
        "\n",
        "xg_classifier = XGBClassifier(**hyperparams)\n",
        "xg_classifier_params = optimization(xg_classifier)\n",
        "\n",
        "print(xg_classifier_params)"
      ],
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: XGBClassifier(base_score=0.5, booster='gbtree', colsample_bylevel=1,\n",
            "              colsample_bynode=1, colsample_bytree=1, gamma=0,\n",
            "              learning_rate=0.3, max_delta_step=0, max_deph=11, max_depth=3,\n",
            "              min_child_weight=1, missing=None, n_estimators=94, n_jobs=1,\n",
            "              nthread=-1, objective='binary:logistic', random_state=0,\n",
            "              reg_alpha=0, reg_lambda=1, scale_pos_weight=9, seed=1909,\n",
            "              silent=True, subsample=1, verbosity=1)\n",
            "{'model__base_score': 0.6699737886943773, 'model__colsample_bylevel': 0.08615916646337052, 'model__colsample_bynode': 0.5493585594031315, 'model__colsample_bytree': 0.5115457995342926, 'model__gamma': 0.28677236250597393, 'model__max_depth': 18, 'model__min_child_weight': 0.9145444378275033, 'model__n_estimators': 112, 'model__subsample': 0.8306506471052306}\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "AzzGIcPscnZL",
        "colab_type": "text"
      },
      "source": [
        "# Evaluating Model with Optimized Parameter"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-Bq8TKCUt_Zs",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "hyperparams = {'seed': 1909, \n",
        "               'learning_rate': 0.3, \n",
        "               'min_child_weight': xg_classifier_params['model__min_child_weight'], \n",
        "               'scale_pos_weight': 8, \n",
        "               'colsample_bylevel': 0.8, # xg_classifier_params['model__colsample_bylevel'], \n",
        "               'colsample_bytree': xg_classifier_params['model__colsample_bytree'], \n",
        "               'colsample_bynode': xg_classifier_params['model__colsample_bynode'], \n",
        "               'max_depth': xg_classifier_params['model__max_depth'], \n",
        "               'n_estimators': xg_classifier_params['model__n_estimators'], \n",
        "               'gamma': xg_classifier_params['model__gamma'], \n",
        "               'subsample': xg_classifier_params['model__subsample'], \n",
        "               'base_score': xg_classifier_params['model__base_score'], \n",
        "               'reg_lambda': 1, \n",
        "               'nthread': -1, 'booster': 'gbtree', \n",
        "               'objective': 'binary:logistic', 'silent': True, \n",
        "               'missing': None, 'max_delta_step': 0\n",
        "}\n",
        "\n",
        "model = XGBClassifier(**hyperparams)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hLpCaYWnx1OG",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "cv = RepeatedStratifiedKFold(n_splits=10, n_repeats=3, random_state=1909)\n",
        "scores = cross_validate(model, X, y, scoring='roc_auc', cv=cv, n_jobs=-1, return_train_score=True)\n",
        "print(f'Mean Roc_Auc Score: {np.mean(scores[\"train_score\"])*100:.2f}/{np.mean(scores[\"test_score\"])*100:.2f}')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "a0C3-sT2vavz",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "cv = RepeatedStratifiedKFold(n_splits=10, n_repeats=3, random_state=1909)\n",
        "scores = cross_validate(model, X, y, scoring='f1', cv=cv, n_jobs=-1, return_train_score=True)\n",
        "print(f'Mean F1 Score: {np.mean(scores[\"train_score\"])*100:.2f}/{np.mean(scores[\"test_score\"])*100:.2f}')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6Yq3wayYwhLT",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.3, random_state = 1909)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gC4O0MskwwZt",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 204
        },
        "outputId": "b3d3a584-840b-4509-d90f-011942bd6de7"
      },
      "source": [
        "model.fit(X_train, y_train)\n",
        "\n",
        "y_pred = model.predict(X_test)\n",
        "\n",
        "print(classification_report(y_pred, y_test))\n",
        "print(confusion_matrix(y_pred, y_test))"
      ],
      "execution_count": 41,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.87      0.98      0.92      8770\n",
            "           1       0.87      0.47      0.61      2351\n",
            "\n",
            "    accuracy                           0.87     11121\n",
            "   macro avg       0.87      0.72      0.76     11121\n",
            "weighted avg       0.87      0.87      0.86     11121\n",
            "\n",
            "[[8601  169]\n",
            " [1256 1095]]\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}